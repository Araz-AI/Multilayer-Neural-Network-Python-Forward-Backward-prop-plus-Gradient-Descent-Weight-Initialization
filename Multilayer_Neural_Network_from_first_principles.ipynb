{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multilayer_Neural_Network_from_first_principles.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNOwZrNmHYsr6tq/j17i130",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Araz-AI/Multilayer-Neural-Network-Python-Forward-Backward-prop-plus-Gradient-Descent-Weight-Initialization/blob/main/Multilayer_Neural_Network_from_first_principles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQo-YHHT4Pm5"
      },
      "source": [
        "#Multilayer Neural Network Forward, Backward Propagation from First Principles with Xavier/He Initialization and Adam, and RMS Prop Optimizers\r\n",
        "#By Araz Jahani, Jan 2021\r\n",
        "#This work uses some of the code and concepts from Andrew NG's DeepLearning Course\r\n",
        "#The Backward propagation is only implemented for Sigmoid function only.  The code for Back propgation of Softmax is not included here.  As a result, this code is only to be used for Sigmoid (Binary classification between 0 and 1 labels)\r\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp3iLHwWeAzt"
      },
      "source": [
        "#Importing Libraries to be used by the program\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import h5py\r\n",
        "import scipy.io\r\n",
        "import sklearn\r\n",
        "import sklearn.datasets\r\n",
        "import math\r\n",
        "import tensorflow as tf\r\n",
        "import PIL\r\n",
        "from PIL import Image\r\n",
        "from numpy import asarray\r\n",
        "import numpy as np\r\n",
        "import matplotlib.image as mpimg\r\n",
        "import math\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#From Andrew NG course  (Cat Versus \"Non Cat\")\r\n",
        "def load_data():\r\n",
        "    train_dataset = h5py.File('/content/drive/My Drive/ColabNotebooks/train_catvnoncat.h5', \"r\")\r\n",
        "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\r\n",
        "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\r\n",
        "\r\n",
        "    test_dataset = h5py.File('/content/drive/My Drive/ColabNotebooks/test_catvnoncat.h5', \"r\")\r\n",
        "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\r\n",
        "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\r\n",
        "\r\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\r\n",
        "    \r\n",
        "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\r\n",
        "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\r\n",
        "    \r\n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ytxo4SkneOKc"
      },
      "source": [
        "def Sigmoid(z):\r\n",
        "    #Sigmoid function calculates the Sigmoid of the matrix X received and would output the sigmoid (x)\r\n",
        "    sigmoid = tf.divide(1,(1+tf.exp(-z)))\r\n",
        "    return sigmoid"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t_RgiZKeQjw"
      },
      "source": [
        "def tanh(z):\r\n",
        "    #tanh function implements the activation function for tanh\r\n",
        "    tanh = tf.divide((tf.exp(z)-tf.exp(-z)),(tf.exp(z)+tf.exp(-z)))\r\n",
        "    return tanh"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKqyn80oeSEL"
      },
      "source": [
        "def Relu(z):\r\n",
        "    relu = tf.maximum(0,z)\r\n",
        "    return relu"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv848aYIeTUv"
      },
      "source": [
        "def LeakyRelu(z, alpha=0.01):\r\n",
        "    #Alpha is by default set at 0.01, however you can also change this variable to suite the degree of \"Leakiness\" that you prefer\r\n",
        "    Leakyrelu = tf.maximum(alpha*z,z)\r\n",
        "    return Leakyrelu"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90gMWk_GAQ8X"
      },
      "source": [
        "def sigmoid_backward(dA, Z):\r\n",
        "  #Calculating Backward propagation for the Sigmoid function\r\n",
        "  \r\n",
        "  sigmoid = Sigmoid(Z)  #Calculating Sigmoid Activation function of the last node of the Neural network (the output node)\r\n",
        "\r\n",
        "  #Below is the calculation of the Sigmoid Backprop\r\n",
        "  dZ = dA * sigmoid * (1-sigmoid)\r\n",
        "  return dZ\r\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MAwUbSYIjBq"
      },
      "source": [
        "def relu_backward(dA, Z):\r\n",
        "\r\n",
        "    dZ = np.array(dA) # Copying dA into a new Array dZ\r\n",
        "\r\n",
        "    #Any values that appear in Z that are below or equal to zero, the correspoding values in dZ are set to 0\r\n",
        "    #Please note an efficient implementation of this is vectorized and the below two for loops is not a good practice nor is it efficient\r\n",
        "    #I used double for loops to demonstrate how logically its implemented but please feel free to change to \"Vectorized implementation\"\r\n",
        "    for i in range(0,dZ.shape[0]):\r\n",
        "      for j in range (0,dZ.shape[1]):\r\n",
        "        if(Z[i][j]<=0):\r\n",
        "          dZ[i][j]=0\r\n",
        "    return dZ"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2OxF-tWIp37"
      },
      "source": [
        "#the following code is from Andrew NG assignments in Deep learning.\r\n",
        "#The below code is using the relu_backward(dA, Z) and the sigmoid_backward(dA, Z) implemented earlier\r\n",
        "def linear_backward(dZ, A_prev, W, b):\r\n",
        "    \r\n",
        "    m = A_prev.shape[1]\r\n",
        "\r\n",
        "    dW = 1./m * np.dot(dZ, np.transpose(A_prev))\r\n",
        "    db = 1./m * np.sum(dZ, axis=1, keepdims=True)\r\n",
        "    dA_prev = np.dot(W.T, dZ)\r\n",
        "    \r\n",
        "    return dA_prev, dW, db\r\n",
        "\r\n",
        "def linear_activation_backward(dA, A_prev,W,b,Z, activation):\r\n",
        "   \r\n",
        "   #Over here we are checking where is our program running in the Neural network. \r\n",
        "   #if the program is running at a node where Relu activation was used then we calculate Relu's backward prop\r\n",
        "    if activation == \"relu\":\r\n",
        "        dZ = relu_backward(dA, Z)\r\n",
        "        dA_prev, dW, db = linear_backward(dZ, A_prev, W, b)\r\n",
        "   #Same as the the Relu case (above), if our activation was Sigmoid, we would use the Sigmoid backward function\r\n",
        "\r\n",
        "    elif activation == \"sigmoid\":\r\n",
        "        dZ = sigmoid_backward(dA, Z)\r\n",
        "        dA_prev, dW, db = linear_backward(dZ, A_prev, W, b)\r\n",
        "      \r\n",
        "    #If you Choose to Implement Softmax, i suggest you include an elif statement to check if the activation was Softmax\r\n",
        "    #in this case we have planned not ot implement with Softmax so i have not included checking for \"Softmax\" here\r\n",
        "    return dA_prev, dW, db"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvud9Sl_eVuU"
      },
      "source": [
        "def softmax (z):\r\n",
        "  #i have included the calculation of Softmax function here.\r\n",
        "  #Just to repeat again that we are not going to use Softmax in this program\r\n",
        "  #if you choose to use softmax, you need to implement the BAckward propagation for Softmax as well\r\n",
        "    t=np.exp(z-np.max(z))\r\n",
        "    sum=np.sum(t, axis=0, keepdims=True)\r\n",
        "    softmax = np.divide(t,sum)\r\n",
        "    return softmax\r\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "genPftFTeXJx"
      },
      "source": [
        "def parameter_initialization (layer_dimension, initialization=\"random\"):\r\n",
        "    #This Function is used to initialize the parameters (Weights = W, and Bias = b) for the entire network depending on the architeture that you choose\r\n",
        "    #Receives a list of the Neural network dimensions as a list.  \r\n",
        "    # so if layer_dimension = [5,10,1], this means that the NN has 3 layers (1 input layer of size 5 (no parameters here), 1 hidden of size 10 and 1 output layers with size 1\r\n",
        "    #The initialization could be just Random, xavier or He inidicated by the \"initialization\" argument.  if user doesnt specify any argument, the default is just a random initialization\r\n",
        "    #The initialization of parameters W (weights) and b (bias) are initialized at random so they are as close to one (1).  \r\n",
        "    #This will help to make the Gradient decent converge faster and does not let the W b to be either very small or very large (Vanishing or Exploding gradients)\r\n",
        "    \r\n",
        "\r\n",
        "    \r\n",
        "    number_of_layers=len(layer_dimension)\r\n",
        "    parameters = {} #This is the dictionary holding parameters W and b.   As you would see in the implementation below, the dictionary \"W1\" corresponds to the Weight matrix of Layer 1\r\n",
        "\r\n",
        "    #The following if statements looks at what initialization in put we have chosen and initializes Weights.  the Biases are initialized to a Zero Vector\r\n",
        "    if (initialization==\"random\"):   #Random Initialization\r\n",
        "        for l in range(1,number_of_layers):\r\n",
        "            parameters['W' + str(l)] = (np.random.randn(layer_dimension[l], layer_dimension[l-1]))*0.1\r\n",
        "            print(\"min W[\",l,\"] is: \",np.min(parameters['W' + str(l)]))\r\n",
        "            print(\"max W[\",l,\"] is: \",np.max(parameters['W' + str(l)]))\r\n",
        "            parameters['b' + str(l)] = np.zeros((layer_dimension[l], 1))\r\n",
        "    elif (initialization==\"xavier\"): #Xavier Initialization\r\n",
        "        for l in range(1,number_of_layers):\r\n",
        "            parameters['W' + str(l)] = np.random.randn(layer_dimension[l], layer_dimension[l-1]) * np.sqrt(np.divide(2,np.add(layer_dimension[l-1],layer_dimension[l])))\r\n",
        "            print(\"min W[\",l,\"] is: \",np.min(parameters['W' + str(l)]))\r\n",
        "            print(\"max W[\",l,\"] is: \",np.max(parameters['W' + str(l)]))\r\n",
        "            parameters['b' + str(l)] = np.zeros((layer_dimension[l], 1))\r\n",
        "    elif (initialization==\"He\"):   #He Initialization\r\n",
        "        for l in range(1,number_of_layers):\r\n",
        "            parameters['W' + str(l)] = np.random.randn(layer_dimension[l], layer_dimension[l-1]) * np.sqrt(np.divide(2,layer_dimension[l-1]))\r\n",
        "            parameters['b' + str(l)] = np.zeros((layer_dimension[l], 1))   \r\n",
        "                                                                                                   \r\n",
        "    #returning Parameter dictionary     \r\n",
        "    return parameters\r\n",
        "    \r\n",
        "    \r\n",
        "    "
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka1SEDBIeYeS"
      },
      "source": [
        "def Forward_prop_per_Layer(x,w,b, activation, Dropout_prob = 1):\r\n",
        "  #This function calculates the forward propagation for each node depending on an activation (ex: Relu, or Sigmoid)\r\n",
        "  #The function receives the initial input Matrix X (or equivalent of A matrix if you are in a hidden layer) and corresponding W (Weights) and Bias (b)\r\n",
        "  #'activation' is an argument that indicates what type of activation function is used at this node (ex: Relu or Sigmoid)\r\n",
        "  #the Dropout probability is an argument indicating regularization using Dropout.  The dropout argument will set some of the Activation matrix (A) to Zero\r\n",
        "  #Drop out is one of the mechanisms to ensure we don't Overfit our model\r\n",
        "  #please note that Softmax is reflected here but the backward propagation is not implemented and hence its not used in the entire program\r\n",
        "  #As a reminder, if you choose to use \"Softmax\" you need to then implement the backward propagation for Softmax function\r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "    #Calculating the Z Value\r\n",
        "    z = tf.add(tf.matmul(w,x),b)\r\n",
        "    a=z\r\n",
        "    \r\n",
        "    #initializing Dropout Matrix in case Dropout prob is less than 1\r\n",
        "    Dropout = np.random.rand(a.shape[0],a.shape[1])\r\n",
        "\r\n",
        "    if (activation==\"Relu\"):\r\n",
        "        a = Relu(z)\r\n",
        "        # Calculating Relu Activation\r\n",
        "          \r\n",
        "    if (activation==\"LeakyRelu\"):\r\n",
        "        a = LeakyRelu(z)\r\n",
        "        # Calculating LeakyRelu Activation\r\n",
        "        \r\n",
        "    if (activation==\"Sigmoid\"):\r\n",
        "        a = Sigmoid(z)\r\n",
        "        # Calculating Sigmoid Activation\r\n",
        "        \r\n",
        "    if (activation==\"Tanh\"):\r\n",
        "        a = tanh(z)\r\n",
        "        # Calculating Tanh Activation (you need to include a function for backward prop if you want to use this activation)        \r\n",
        "        \r\n",
        "    if (activation==\"Softmax\"):\r\n",
        "        a = softmax(z)\r\n",
        "        # Calculating Softmax Activation (you need to include a function for backward prop if you want to use this activation)        \r\n",
        "\r\n",
        "    #The Dropout is calculated in the event that the Dropout Probability is below 100% (or below '1' in this case)    \r\n",
        "    if (Dropout_prob<1 and activation!=\"Sigmoid\"):\r\n",
        "\r\n",
        "        Dropout = (Dropout < Dropout_prob).astype(np.float)\r\n",
        "        a = tf.multiply(a,Dropout)\r\n",
        "        a = tf.divide(a,Dropout_prob)\r\n",
        "\r\n",
        "\r\n",
        "    return a,z,Dropout\r\n",
        "        \r\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ9GUAmDeZ24"
      },
      "source": [
        "def Forward_prop_End_to_End(X, y, layer_dimension_list,parameters, activation_list,lambda_reg=0,Dropout_prob = 1):\r\n",
        "    #This function uses forward propagation at each node which is implemneted in function: def Forward_prop_per_Layer(x,w,b, activation, Dropout_prob = 1)\r\n",
        "    #This function calculates the forward E2E propagation of the Neural Network\r\n",
        "    #the inputs are X matrix (The initial input matrix), y labels (True labels), layer_dimension_list (the list containg nodes at each layer), activation_list (list of Activation used at each layer)\r\n",
        "    #lambda_reg --> lambda regularization parameter if you choose to prevent overfitting of the model\r\n",
        "    #Dropout_prob --> Another mechanism to prevent overfitting if the probability is less than 100% (or below 1)\r\n",
        "\r\n",
        "    A_prev = X                    #assigns the input Activation matrix to A_prev\r\n",
        "    L=len(layer_dimension_list)   #Captures the length of the layers in the NN\r\n",
        "    cache = {}                    #Cache dictionary which stores the Values of Activation Matrices A and also Z matrices\r\n",
        "    Dropout_cache={}              #Captures the dropout matrix D\r\n",
        "    Reg_cost=0                    #sets regularization cost to 0\r\n",
        "    cost=0                        #sets initial cost to 0\r\n",
        "    m=A_prev.shape[1]             #caputures the number of samples (m) from the y-axis of the Activation Matrix\r\n",
        "    \r\n",
        "    for i in range (1, len(layer_dimension_list)):\r\n",
        "        #This section of the code (For loop), calculates the Activation at each node using Weights, Biases and stores the Z and A matrix into the Cache\r\n",
        "        A,Z,D = Forward_prop_per_Layer(A_prev,parameters['W' + str(i)],parameters['b' + str(i)], activation_list[i],Dropout_prob)\r\n",
        "        cache['A' + str(i)]=A\r\n",
        "        cache['Z' + str(i)]=Z\r\n",
        "        \r\n",
        "        A_prev=A \r\n",
        "        Dropout_cache['D' + str(i)]=D   #Stores D in Dropout_cache.. If Dropout is NOT used, then this Matrix would not be used \r\n",
        "        Reg_cost= Reg_cost+Regularization_Cost(parameters['W' + str(i)], lambda_reg)   #calculating Regularization Cost. If regularization is NOT used, this cost is Zero\r\n",
        "\r\n",
        "\r\n",
        " \r\n",
        "    if (activation_list[-1]==\"Sigmoid\"): \r\n",
        "      #Binary Cross Entropy Cost\r\n",
        "      cost = Cost(cache['A' + str(L-1)],y) + Reg_cost\r\n",
        "      \r\n",
        "    if (activation_list[-1]==\"Softmax\"): \r\n",
        "      #As a reminder again, This is just a placeholder in case you want to Use Softmax.  If you Choose to use Softmax, I suggest you implement the backward propagation for it\r\n",
        "      #categorical Cross Entropy Cost should be used for Softmax\r\n",
        "      cost=cross_entropy_cost(cache['A' + str(L-1)],y)\r\n",
        "\r\n",
        "    return cost, cache,Dropout_cache\r\n",
        "    \r\n",
        "    "
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNmeIPc7ebU_"
      },
      "source": [
        "def Regularization_Cost(W, lambda_reg):\r\n",
        "    #This function calculates the regulization cost which is the Frobenius norm for the sum of Matrices W at each layer\r\n",
        "    #the regularization cost will be added to the overall cost if Regularization is used\r\n",
        "    #if not Regularization is used, therefore \"lambda_reg\" will be set to Zero and will make the Reg_cost (below) Zero as well.\r\n",
        "    Reg_cost = lambda_reg/(2*(W.shape[1])) * (np.sum(tf.square(W)))\r\n",
        "    return Reg_cost"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSEupkbXeeNs"
      },
      "source": [
        "def Cost(A_prev,y):\r\n",
        "    #this function calculates the cost based on the difference between the A-Matrix output from the last layer of the Neural network and the True label (y matrix)\r\n",
        "    #Binary Cross Entropy Cost used for Sigmoid Activation function\r\n",
        "    #A_prev matrix is a matrix as a result of Sigmoid Activation function from last node of the NN\r\n",
        "\r\n",
        "    m = y.shape[1]    #Capturing size of the samples from true label matrix (y)\r\n",
        "    cost1 = np.multiply(-np.log(A_prev),y)\r\n",
        "    cost2 =  np.multiply(-np.log(1-A_prev), 1 - y)\r\n",
        "\r\n",
        "    cost = (1./m)*np.nansum(cost1+cost2)  #Useful Note here:  Nansum would ignore the 'nan' output of the logarithm function of a zero\r\n",
        "    return cost"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1NsZe7luiBt"
      },
      "source": [
        "def cross_entropy_cost(A,y):\r\n",
        "  #categorical Cross Entropy loss used for Softmax\r\n",
        "  #as a reminder again, we are not implementing the entire NN with softmax, so i encourage you to revise and implement this code with Softmax as well\r\n",
        "  #A is the activation matrix as a result of Softmax output\r\n",
        "    \r\n",
        "    epsilon=1e-12 #This is to avoid calculating log of zero\r\n",
        "    m = y.shape[0]\r\n",
        "    log_prob = -np.log(A[range(m),y]+epsilon)\r\n",
        "    Categorical_loss = np.sum(log_prob) / m\r\n",
        "    return Categorical_loss\r\n",
        "    "
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye-JsdqKefve"
      },
      "source": [
        "def FirstLayer(num_nodes, label, activation=\"null\"):\r\n",
        "    #This is used in structuring the First layer\r\n",
        "    return num_nodes,label,activation\r\n",
        "    "
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF6VpaekeiMw"
      },
      "source": [
        "def Layer(num_nodes, label, activation):\r\n",
        "    #This layer returns the number of nodes and activations that are responsible to construct the network (except for the first layer)\r\n",
        "    return num_nodes,label,activation"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjn85Oafejwc"
      },
      "source": [
        "def add_Layer_sequence(Layer, cache):\r\n",
        "    Cache.append(Layer)\r\n",
        "    return Cache"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydQul5QxnjDJ"
      },
      "source": [
        "def normalizeData(x):\r\n",
        "  #this function is used to normalize the data.  It is useful if some of the data is on a different scale\r\n",
        "  #ex: your data contains housing prices in the millions but your number of bedrooms are between 1 through 10.  As a result, your data is not on the same scale and needs to be normalized\r\n",
        "  \r\n",
        "  mean = np.mean(x)\r\n",
        "  stddev = np.std(x)\r\n",
        "  normalized = np.divide(np.subtract(x,mean),stddev)\r\n",
        "  return normalized"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YU5yHXTemgV"
      },
      "source": [
        "def Back_prop_per_Layer(x,y,parameters, cache, Dropout_cache, lambda_reg, Dropout_prob = 1):\r\n",
        "    #calculates End to End back propagation for the Neural Network given parameters dictionary, input matrix (x), true label vector (y), Drop_cache matrix (if Dropout was applied) and regularization parameter Lambda\r\n",
        "    #The outputs of this function are gradients dA, dZ, dW and db which will be used in the gradient decent calculations\r\n",
        "\r\n",
        "    #initialization of dictionary gradients to store gradients. Similar to the format used in \"parameters\" the gradient at each layer is added to the dictionary keys (ex: dZ3 refers to the dZ at layer #3)\r\n",
        "    gradients = {}  \r\n",
        "\r\n",
        "    #Allocating Lists corresponding to each matrix D from Dropout_cache\r\n",
        "    D=[]\r\n",
        "\r\n",
        "    #calculating the length of the items in Cache\r\n",
        "    L_cache = len(cache)\r\n",
        "    L= int(L_cache/2) \r\n",
        "\r\n",
        "    #Storing the x (input matrix) in A0\r\n",
        "    cache['A' + str(0)]=x\r\n",
        "    \r\n",
        "    #capturing length of dictionary parameters\r\n",
        "    P = len(parameters)\r\n",
        "\r\n",
        "    m = x.shape[1]\r\n",
        "\r\n",
        "    #First Starting from the output of the last node and calculating the delta between true labels and the output of the Neural network (Matrix A)\r\n",
        "    dAL = - (np.divide(y, cache['A' + str(L)]) - np.divide(1 - y, 1 - cache['A' + str(L)]))\r\n",
        "\r\n",
        "    #capturing the output of the \"linear_activation_backward\" function and capturing the gradients dA,dW and db of the Sigmoid function\r\n",
        "    #Please note that if you are going to implement Softmax, then you need to implement Softmax backprop code in the \"linear_activation_backward\" function and change the last argument of this function to \"Softmax\"\r\n",
        "    gradients[\"dA\" + str(L-1)], gradients[\"dW\" + str(L)], gradients[\"db\" + str(L)] = linear_activation_backward(dAL,cache['A' + str(L-1)],parameters[\"W\"+ str(L)],parameters[\"b\"+ str(L)],cache['Z' + str(L)], \"sigmoid\")\r\n",
        "\r\n",
        "   \r\n",
        "    #Now that we have captured the backprop for the Sigmoid function above, lets loop through all the remaining layers (going backward) and calculating the gradients dA, dW, and db\r\n",
        "    for i in range(L-1,0,-1): \r\n",
        "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(gradients[\"dA\" + str(i)],cache['A' + str(i-1)],parameters[\"W\"+ str(i)],parameters[\"b\"+ str(i)],cache['Z' + str(i)], \"relu\")\r\n",
        "\r\n",
        "        if((i-1)!=0):  #I have put this if statement so to avoid the dA0\r\n",
        "          gradients[\"dA\" + str(i-1)] = dA_prev_temp\r\n",
        "          if (Dropout_prob<1): \r\n",
        "            D = np.random.rand(gradients['dA' + str(i-1)].shape[0],gradients['dA' + str(i-1)].shape[1])              # Step 1: Apply mask D2 to shut down the same neurons as during the forward propagation\r\n",
        "            D = (D < Dropout_prob).astype(int) \r\n",
        "            gradients['dA' + str(i-1)] = np.multiply(gradients['dA' + str(i-1)],Dropout_cache['D' + str(i-1)]) \r\n",
        "            gradients['dA' + str(i-1)] = gradients['dA' + str(i-1)]/Dropout_prob                                      # Step 2: Scale the value of neurons that haven't been shut down\r\n",
        "        \r\n",
        "        gradients['dW' + str(i)] = dW_temp\r\n",
        "        gradients['db' + str(i)] = db_temp\r\n",
        "     \r\n",
        "        \r\n",
        "      \r\n",
        "    return gradients"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um3NriCdeoih"
      },
      "source": [
        "def gradient_decent(parameters,gradients,alpha,GD_Type=\"GD\", B1=0.9,B2=0.999, epsilon=1e-8,t=1):\r\n",
        "  #The purpose of this function is to calculate Gradient Decent\r\n",
        "  #There are three options included:  a)simple Gradient Decent (default), b) RMSProp and c)ADAM --> indicated by GD_Type\r\n",
        "  #for Adam B1, B2 and epsilon are used\r\n",
        "  #This function accepts arguments for parameters and the gradients calculated in the \"Back_prop_per_Layer\" Function and will output the update Parameter Weights and biases\r\n",
        "  #These new Parameters Weights (W) and biases (b) will then be used to calculate/predict a new Matrix A at the sigmoid layer of the neural network\r\n",
        "\r\n",
        "    #Defining Length of Parameter dictionary containing current values of Weights (W) and Biases (b)\r\n",
        "    L=int(len(parameters)/2)\r\n",
        "\r\n",
        "    #Creating new dictionaries to facilitate calculations for RMSProp and ADAM optimizers\r\n",
        "    v={}\r\n",
        "    s={}\r\n",
        "    V_Corrected={}\r\n",
        "    S_Corrected={}\r\n",
        "\r\n",
        "    #Creating and Initializing gradient matrix placeholders in our V and S dictionaries as Zero Numpy Arrays    \r\n",
        "    for i in range(1,L+1):   \r\n",
        "        v[\"dW\" + str(i)] = np.zeros((parameters[\"W\" + str(i)]).shape)\r\n",
        "        v[\"db\" + str(i)] = np.zeros((parameters[\"b\" + str(i)]).shape)\r\n",
        "        s[\"dW\" + str(i)] = np.zeros((parameters[\"W\" + str(i)]).shape)\r\n",
        "        s[\"db\" + str(i)] = np.zeros((parameters[\"b\" + str(i)]).shape)\r\n",
        "     \r\n",
        "        \r\n",
        "   \r\n",
        "    for i in range(1,L+1):   #Looping through all the layers  to update corresponding values for Weights (W) and Biases (b) \r\n",
        "        \r\n",
        "        if(GD_Type==\"RMSProp\"):   #This Block calculates RMSProp\r\n",
        "\r\n",
        "            s[\"dW\" + str(i)] = B2*s[\"dW\" + str(i)]+(1-B2)*np.power(gradients['dW' + str(i)],2)\r\n",
        "            s[\"db\" + str(i)] = B2*s[\"db\" + str(i)]+(1-B2)*np.power(gradients['db' + str(i)],2)\r\n",
        "            parameters['W' + str(i)]=parameters['W' + str(i)]-alpha*(gradients['dW' + str(i)]/(np.sqrt(s[\"dW\" + str(i)])+epsilon))\r\n",
        "            parameters['b' + str(i)]=parameters['b' + str(i)]-alpha*(gradients['db' + str(i)]/(np.sqrt(s[\"db\" + str(i)])+epsilon)) \r\n",
        "\r\n",
        "        if(GD_Type==\"ADAM\"):     #This Block calculates ADAM\r\n",
        "            v[\"dW\" + str(i)] = B1*v[\"dW\" + str(i)]+(1-B1)*gradients['dW' + str(i)]\r\n",
        "            v[\"db\" + str(i)] = B1*v[\"db\" + str(i)]+(1-B1)*gradients['db' + str(i)]\r\n",
        "\r\n",
        "            V_Corrected[\"dw\" + str(i)] = v[\"dW\" + str(i)]/(1-np.power(B1,t))\r\n",
        "            V_Corrected[\"db\" + str(i)] = v[\"db\" + str(i)]/(1-np.power(B1,t))\r\n",
        "\r\n",
        "            s[\"dW\" + str(i)] = B2*s[\"dW\" + str(i)]+(1-B2)*np.power(gradients['dW' + str(i)],2)\r\n",
        "            s[\"db\" + str(i)] = B2*s[\"db\" + str(i)]+(1-B2)*np.power(gradients['db' + str(i)],2)\r\n",
        "\r\n",
        "            S_Corrected[\"dW\" + str(i)] = s[\"dW\" + str(i)]/(1-np.power(B2,t))\r\n",
        "            S_Corrected[\"db\" + str(i)] = s[\"db\" + str(i)]/(1-np.power(B2,t))       \r\n",
        "\r\n",
        "            parameters['W' + str(i)]=parameters['W' + str(i)]-alpha*(V_Corrected[\"dw\" + str(i)]/(np.sqrt(S_Corrected[\"dW\" + str(i)])+epsilon))\r\n",
        "            parameters['b' + str(i)]=parameters['b' + str(i)]-alpha*(V_Corrected[\"db\" + str(i)]/(np.sqrt(S_Corrected[\"db\" + str(i)])+epsilon)) \r\n",
        "            \r\n",
        "            \r\n",
        "        if (GD_Type==\"GD\"):   #This Block calculates simple Gradient Decent which does not have any momentum and will take longer to converge in comparison to ADAM And RMSPROP\r\n",
        "\r\n",
        "            \r\n",
        "            parameters['W' + str(i)]=parameters['W' + str(i)]-alpha*gradients['dW' + str(i)]\r\n",
        "            parameters['b' + str(i)]=parameters['b' + str(i)]-alpha*gradients['db' + str(i)]\r\n",
        "            \r\n",
        "\r\n",
        "            \r\n",
        "    return parameters"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpZH6N6p8F5t"
      },
      "source": [
        "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\r\n",
        "  #From Andrew NG course\r\n",
        "    \"\"\"\r\n",
        "    Creates a list of random minibatches from (X, Y)\r\n",
        "    \r\n",
        "    Arguments:\r\n",
        "    X -- input data, of shape (input size, number of examples)\r\n",
        "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\r\n",
        "    mini_batch_size - size of the mini-batches, integer\r\n",
        "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\r\n",
        "    \r\n",
        "    Returns:\r\n",
        "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    m = X.shape[1]                  # number of training examples\r\n",
        "    mini_batches = []\r\n",
        "    np.random.seed(seed)\r\n",
        "    \r\n",
        "    # Step 1: Shuffle (X, Y)\r\n",
        "    permutation = list(np.random.permutation(m))\r\n",
        "    shuffled_X = X[:, permutation]\r\n",
        "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\r\n",
        "\r\n",
        "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\r\n",
        "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\r\n",
        "    for k in range(0, num_complete_minibatches):\r\n",
        "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\r\n",
        "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\r\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\r\n",
        "        mini_batches.append(mini_batch)\r\n",
        "    \r\n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\r\n",
        "    if m % mini_batch_size != 0:\r\n",
        "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\r\n",
        "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\r\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\r\n",
        "        mini_batches.append(mini_batch)\r\n",
        "    \r\n",
        "    return mini_batches"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DodlBrV65Q9x"
      },
      "source": [
        "def Convert_to_batches(X, Y, mini_batch_size = 64):\r\n",
        "  #From Andrew NG course\r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "    np.random.seed(0)            # To make your \"random\" minibatches the same as ours\r\n",
        "    m = X.shape[1]                  # number of training examples\r\n",
        "    mini_batches = []\r\n",
        "\r\n",
        "    # Step 1: Shuffle (X, Y)\r\n",
        "    permutation = list(np.random.permutation(m))\r\n",
        "    shuffled_X = X[:, permutation]\r\n",
        "    shuffled_Y = Y[:, permutation].reshape((1,m))\r\n",
        "\r\n",
        "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\r\n",
        "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\r\n",
        "\r\n",
        "    for k in range(0, num_complete_minibatches):\r\n",
        "        ### START CODE HERE ### (approx. 2 lines)\r\n",
        "        mini_batch_X = shuffled_X[:, k* mini_batch_size : (k+1) * mini_batch_size]\r\n",
        "        mini_batch_Y = shuffled_Y[:, k* mini_batch_size : (k+1) * mini_batch_size]\r\n",
        "        ### END CODE HERE ###\r\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\r\n",
        "        mini_batches.append(mini_batch)\r\n",
        "   \r\n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\r\n",
        "    if m % mini_batch_size != 0:\r\n",
        "        ### START CODE HERE ### (approx. 2 lines)\r\n",
        "        mini_batch_X = shuffled_X[:, num_complete_minibatches*mini_batch_size:m]\r\n",
        "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches*mini_batch_size:m]\r\n",
        "        ### END CODE HERE ###\r\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\r\n",
        "        mini_batches.append(mini_batch)\r\n",
        "    \r\n",
        "    return mini_batches"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU6GPuMQUCYd"
      },
      "source": [
        "def predict(X,Y,threshold, layer_dimension_list,parameters, activation_list):\r\n",
        "  #The purpose of this function is to predict the outcome with the trained parameters\r\n",
        "  #The function uses X (input matrix), y(true labels), list of dimensions at each layer, parameters, and list of activations at each layer\r\n",
        "  #Please note that in the Predict function, typically Y vector (True labels) is not passed as an argument, but i am passing it here in order to calculate the Accuracy, MSE (Mean Squared Error)\r\n",
        "  # in the argument we are also receiving \"Threshold\" which is basically tells us what should be our prediction cut-off limit.  For example, do we want to curtail values of Matrix A that are above 50%? or above 70%? etc..\r\n",
        "\r\n",
        "  #Using the Standard Forward Prop function to receive cache which contains the last activation Matrix\r\n",
        "  cost, cache, Dropout_cache=Forward_prop_End_to_End(X, Y, layer_dimension_list,parameters, activation_list,lambda_reg=0,Dropout_prob = 1)\r\n",
        "\r\n",
        "  #Extracting the Last activation matrix (A) from the cache\r\n",
        "  L=len(layer_dimension_list)\r\n",
        "  A = cache['A' + str(L-1)]\r\n",
        "\r\n",
        "  m = X.shape[1]\r\n",
        "  n=  Y.shape[1]\r\n",
        " \r\n",
        "  #creating Matrix P with the same shape as the True label matrix Y (also the dimensions should match the last A matrix)\r\n",
        "  p = np.zeros((Y.shape[0],Y.shape[1]))\r\n",
        "\r\n",
        "  # Any probabilities in Matrix A that are above our threshold, we are considering those as '1'.\r\n",
        "  #please note that the following code can also be written in a Vectorized version to be more efficient and avoid the O(N2) complexity\r\n",
        "  for i in range(0, A.shape[0]):\r\n",
        "    for j in range (0,A.shape[1]):\r\n",
        "      if A[i,j] > threshold:\r\n",
        "        p[i,j] = 1\r\n",
        "      else:\r\n",
        "        p[i,j] = 0\r\n",
        "\r\n",
        "  #Calculating MSE (Mean Squared Error), Accuracy and Mean Absolute Error\r\n",
        "  MSE = (1/n)*np.sum(np.power(np.subtract(Y,A),2))\r\n",
        "  Accuracy= np.sum((p == Y)/m)\r\n",
        "  MAE=np.sum(np.absolute((p.astype(\"float\") - Y.astype(\"float\"))))\r\n",
        "\r\n",
        "  return p,MSE, MAE, Accuracy"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cmmuBZdG8i4",
        "outputId": "ae258fc4-bc37-4774-e0ad-7411a5d2ae05"
      },
      "source": [
        "\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_data()\r\n",
        "print(\"X_train_orig shape is: \",X_train_orig.shape)\r\n",
        "print(\"Y_train_orig shape is: \",Y_train_orig.shape)\r\n",
        "\r\n",
        "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\r\n",
        "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\r\n",
        "\r\n",
        "X_train = X_train_flatten/255.\r\n",
        "X_test = X_test_flatten/255.\r\n",
        "\r\n",
        "x=X_train\r\n",
        "y=Y_train_orig\r\n",
        "\r\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "X_train_orig shape is:  (209, 64, 64, 3)\n",
            "Y_train_orig shape is:  (1, 209)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FOm8EUcepzN"
      },
      "source": [
        "def Fit_Model (x,y, parameters, layer_dimension,activations,labels, Epochs,learning_rate ,GD_Type=\"ADAM\",threshold=0.5,mini_batch_size = 1,lambda_reg=0,Dropout_prob = 1,B1=0.9,B2=0.999, epsilon=1e-8):\r\n",
        "#This function implements the entire forward and backward propagation using the type of Gradient Decent or Optimizer as well as the number of Epochs and Learning Rate (Alpha)\r\n",
        "#It takes as inputs, x (the input matrix), y (the true lable), layers_dimension (the list of layers and and number of nodes and corresponding labels and activations)\r\n",
        "#Other inputs are: Epochs (number of iterations to achieve optimality in reduction of cost), learning rate (Alpha rate for optimizer), GD_Type (Optimzer type), Threshold (Binary classification threshold)\r\n",
        "#other inputs include: Mini_batch_size (by default its set to '1' which represents the Stochastic Gradient Decent (SGD)) and also lambda regularization and Dropout_prob\r\n",
        "\r\n",
        "  #Assigning the number of Epochs to iterations that will be used in our 'for' loop\r\n",
        "  iterations=Epochs \r\n",
        "  t=0   \r\n",
        "\r\n",
        "  #creating Cost list so that Cost can be tracked\r\n",
        "  cost_tracker=np.empty(iterations)\r\n",
        "  cost_tracker_test=np.empty(iterations)\r\n",
        "  cost_tracker_mini=[]\r\n",
        "\r\n",
        "  #Creating place holder to track MSE, MAE and Accuracy that we receive from the Predict function\r\n",
        "  MSE_Train=np.empty(iterations)\r\n",
        "  MSE_Test=np.empty(iterations)\r\n",
        "  MAE_Train=np.empty(iterations)\r\n",
        "  MAE_Test=np.empty(iterations)\r\n",
        "  accuracy_train=np.empty(iterations)\r\n",
        "  accuracy_test=np.empty(iterations)\r\n",
        "\r\n",
        "\r\n",
        "  #Using the Batch functions to feed our data as mini batches instead of one huge batch\r\n",
        "  #Please note that the its recommended that we pick our mini batch size in power of 2s.  ex:  32, 64, 128, 256....\r\n",
        "  #Also, if you are not using pictures and don't want to use mini batches just comment this code out plus the mini batch second for loop below\r\n",
        "  Mini_batch=Convert_to_batches(x, y, mini_batch_size)\r\n",
        "  Mini_batch=random_mini_batches(x, y, mini_batch_size)\r\n",
        "\r\n",
        "\r\n",
        "  #Running our EPOCHS (Iterations)\r\n",
        "  for i in range (0,iterations):\r\n",
        "    for j in Mini_batch:  #this for loop is intended for mini batch iterations.  Comment this out if you don't want to use mini batches\r\n",
        "      (x,y)=j             #comment this line if you don't want to use mini-batches\r\n",
        "      \r\n",
        "      #calling the End-to-End Forward Propagation function here to capture the Cost, Cache. Cache contains matrices A, Dropout and Z\r\n",
        "      cost, cache, Dropout_cache=Forward_prop_End_to_End(x, y, layer_dimension,parameters, activations,lambda_reg,Dropout_prob)\r\n",
        "           \r\n",
        "      #capturing Cost\r\n",
        "      cost_tracker_mini.append(cost)\r\n",
        "      cost_tracker[i]=(cost)\r\n",
        "\r\n",
        "      #Calling Backprop function and receiving the gradients    \r\n",
        "      grads = Back_prop_per_Layer(x,y,parameters, cache,Dropout_cache,lambda_reg, Dropout_prob )\r\n",
        "\r\n",
        "      t+=1 #updating the iterations for ADAM optimizer\r\n",
        "\r\n",
        "      #Calling the gradient_decent function and using the gradients we have received from the Backprop function to obtain the new parameters\r\n",
        "      parameters = gradient_decent(parameters,grads,learning_rate,GD_Type, B1,B2, epsilon,t)\r\n",
        "    \r\n",
        "    #Calling Predict functions on the Train data as well as the test data to observe the MSE, MAE and Accuracy\r\n",
        "    p_train,Mean_squared_Train, MAE_train, Accuracy_train1 = predict(X_train,Y_train_orig,threshold,layer_dimension,parameters, activations)\r\n",
        "    p_test,Mean_squared_Test,MAE_test, accuracy_test1 = predict(X_test,Y_test_orig,threshold,layer_dimension,parameters, activations)\r\n",
        "\r\n",
        "    print(\"\\n*Cost for Training data at Epoch:\",i,\"is: \", cost)\r\n",
        "\r\n",
        "    #Capturing the output of the predict function\r\n",
        "    ACC_train = Accuracy_train1\r\n",
        "    ACC_test=accuracy_test1\r\n",
        "\r\n",
        "    accuracy_train[i]=ACC_train\r\n",
        "    accuracy_test[i]=ACC_test\r\n",
        "    MSE_Train[i] = Mean_squared_Train\r\n",
        "    MSE_Test[i] = Mean_squared_Test\r\n",
        "    MAE_Train[i]=MAE_train\r\n",
        "    MAE_Test[i]=MAE_test\r\n",
        "    \r\n",
        "    #printing Status per Epoch\r\n",
        "    print(\" Accuracy_Train: \", ACC_train)\r\n",
        "    print(\" Accuracy_Test: \", ACC_test)\r\n",
        "    print(\" MSE of Training data at current Epoch is: \",Mean_squared_Train)\r\n",
        "    print(\" MSE of Test data at current Epoch is: \",Mean_squared_Test)\r\n",
        "    print(\" MAE of Training data at current Epoch is: \",MAE_train)\r\n",
        "    print(\" MAE of Test data at current Epoch is: \",MAE_test)\r\n",
        "\r\n",
        "  return cost_tracker,accuracy_train,accuracy_test,MSE_Train,MSE_Test,MAE_Train,MAE_Test\r\n",
        "\r\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uay5L7x2sie3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2631fc75-3596-4830-c761-65d49a757812"
      },
      "source": [
        "#This is where the actual Code gets executed and the place where we call all of our functions to run all of our functions\r\n",
        "\r\n",
        "#cache to capture the details of our layers\r\n",
        "cache=[]  \r\n",
        "\r\n",
        "#Creating the layers.  Please feel free to add more layers or subtract.  you just need to maintain minimum two layers (the First layer and the last_layer)\r\n",
        "#Please make sure that for your first layer the input dimensions match the X.shape[0].  The last layer has 1 node and this represents the \"Sigmoid\" binary output\r\n",
        "#if you decide to implement Softmax's backdrop, you can change the last layer to \"Softmax\" and change the nodes to the different softmax classes, but just as a reminder that you need to implemnt the backward prop for Softmax first\r\n",
        "#other activation functions in hidden layers include: \"LeakyRelu\", \"Tanh\", \r\n",
        "first_layer = FirstLayer(12288, \"First Layer\")\r\n",
        "second_layer = Layer(100,\"Second Layer\", \"LeakyRelu\")\r\n",
        "third_layer = Layer(50, \"Third Layer\",\"LeakyRelu\")\r\n",
        "last_layer= Layer(1, \"Last Layer\", \"Sigmoid\")\r\n",
        "\r\n",
        "#Adding the Layers in sequence to the cache\r\n",
        "#if you add more layers above, please include the name and append them accordingly to the cache below\r\n",
        "cache.append(first_layer)\r\n",
        "cache.append(second_layer)\r\n",
        "cache.append(third_layer)\r\n",
        "cache.append(last_layer)\r\n",
        "\r\n",
        "\r\n",
        "#Defining each list within the Cache so that we can extract these data from the Cache\r\n",
        "layer_dimension=[]\r\n",
        "activations = []\r\n",
        "labels = []\r\n",
        "\r\n",
        "#Extracting the data from the cache\r\n",
        "layer_dimension.append(cache[0][0])  \r\n",
        "activations.append(cache[0][2])\r\n",
        "labels.append(cache[0][1])\r\n",
        "\r\n",
        "for i in range (1, len(cache)):\r\n",
        "    layer_dimension.append(cache[i][0])\r\n",
        "    activations.append(cache[i][2])\r\n",
        "    labels.append(cache[i][1])\r\n",
        "\r\n",
        "#The parameter_initialization function would automatically calculate the dimensions of your W Matrices and will initialize them based on the input you provide\r\n",
        "#Other possible initializations are: \"He\", \"xavier\" or \"random\"\r\n",
        "parameters=parameter_initialization (layer_dimension, initialization=\"He\")\r\n",
        "cost_tracker,accuracy_train,accuracy_test,MSE_Train,MSE_Test,MAE_Train,MAE_Test=Fit_Model (x,y,parameters,layer_dimension,activations,labels,Epochs=1000,learning_rate=0.01 ,GD_Type=\"GD\",threshold=0.5,mini_batch_size = 32,lambda_reg=0.0,Dropout_prob = 1,B1=0.9,B2=0.999, epsilon=1e-8)                          "
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "*Cost for Training data at Epoch: 375 is:  0.0015561059393910557\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  4.081976679055312e-05\n",
            " MSE of Test data at current Epoch is:  0.20279431673374493\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 376 is:  0.0015466678138058494\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  4.065197945330566e-05\n",
            " MSE of Test data at current Epoch is:  0.20273157459676658\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 377 is:  0.001541296934117603\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.9875014185563985e-05\n",
            " MSE of Test data at current Epoch is:  0.20263110563642692\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 378 is:  0.001531148395806966\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.957316388044184e-05\n",
            " MSE of Test data at current Epoch is:  0.20275793018860772\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 379 is:  0.0015289178374002451\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.8982699408839086e-05\n",
            " MSE of Test data at current Epoch is:  0.2029479307889713\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 380 is:  0.0015178378572987207\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.859391911042414e-05\n",
            " MSE of Test data at current Epoch is:  0.2028843769098239\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 381 is:  0.0015141282810120947\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.8052748785774136e-05\n",
            " MSE of Test data at current Epoch is:  0.2028172353673228\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 382 is:  0.001498043751478657\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.702305592153107e-05\n",
            " MSE of Test data at current Epoch is:  0.2029869556303526\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 383 is:  0.0014968777812887832\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.7268915386723144e-05\n",
            " MSE of Test data at current Epoch is:  0.20296083795300257\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 384 is:  0.00148324470161394\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.640673798665439e-05\n",
            " MSE of Test data at current Epoch is:  0.2030356328906322\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 385 is:  0.001480409877525792\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.586725782207954e-05\n",
            " MSE of Test data at current Epoch is:  0.2031778198679847\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 386 is:  0.0014720078912852177\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.557346408631614e-05\n",
            " MSE of Test data at current Epoch is:  0.20305745276747986\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 387 is:  0.0014696319358458733\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.537486089832101e-05\n",
            " MSE of Test data at current Epoch is:  0.20313017268931555\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 388 is:  0.0014551112839267105\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.45521051400303e-05\n",
            " MSE of Test data at current Epoch is:  0.20325649381875863\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 389 is:  0.0014526836412372829\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.415396637545445e-05\n",
            " MSE of Test data at current Epoch is:  0.2033730559006012\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 390 is:  0.001442658070514236\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.379224272698232e-05\n",
            " MSE of Test data at current Epoch is:  0.2032483058408708\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 391 is:  0.0014408246327799773\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.3451289758833445e-05\n",
            " MSE of Test data at current Epoch is:  0.20329526972878406\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 392 is:  0.0014265322287278775\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.278938714579097e-05\n",
            " MSE of Test data at current Epoch is:  0.2034745719861239\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 393 is:  0.0014224703564734943\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.258254870790329e-05\n",
            " MSE of Test data at current Epoch is:  0.20347648076751218\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 394 is:  0.0014181141746824047\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.239333947232768e-05\n",
            " MSE of Test data at current Epoch is:  0.20333632701223991\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 395 is:  0.0014103892416927354\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.177573245340921e-05\n",
            " MSE of Test data at current Epoch is:  0.20349391031404593\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 396 is:  0.001400596715055926\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.106447825099119e-05\n",
            " MSE of Test data at current Epoch is:  0.20368553497447664\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 397 is:  0.001395807066970569\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.1087202345937426e-05\n",
            " MSE of Test data at current Epoch is:  0.20362791203207678\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 398 is:  0.0013900649032773222\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.075154747040363e-05\n",
            " MSE of Test data at current Epoch is:  0.2035048874973307\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 399 is:  0.001385879858306331\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  3.0366144223706888e-05\n",
            " MSE of Test data at current Epoch is:  0.20361224481075013\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 400 is:  0.0013780128389947602\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.9961009107359103e-05\n",
            " MSE of Test data at current Epoch is:  0.2037673584460481\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 401 is:  0.001373363289702256\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.9580675913682458e-05\n",
            " MSE of Test data at current Epoch is:  0.20364771032849113\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 402 is:  0.0013619222285015458\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.89537366435441e-05\n",
            " MSE of Test data at current Epoch is:  0.2037532890974242\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 403 is:  0.0013583213981978258\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.9081264599095094e-05\n",
            " MSE of Test data at current Epoch is:  0.20376708418774708\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 404 is:  0.0013505729945495093\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.8601591656675197e-05\n",
            " MSE of Test data at current Epoch is:  0.2038573728722315\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 405 is:  0.0013489374580544237\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.820547047671332e-05\n",
            " MSE of Test data at current Epoch is:  0.2039644844008726\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 406 is:  0.0013404850963079343\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.7932137824486354e-05\n",
            " MSE of Test data at current Epoch is:  0.20383987961513142\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 407 is:  0.0013347443035253165\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.7539831066149165e-05\n",
            " MSE of Test data at current Epoch is:  0.20391971847424636\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 408 is:  0.0013266632122008065\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.7363001233490742e-05\n",
            " MSE of Test data at current Epoch is:  0.20400262326206142\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 409 is:  0.0013240571183900215\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.7214043676735755e-05\n",
            " MSE of Test data at current Epoch is:  0.2040562277982899\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 410 is:  0.0013174130533469132\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.6791716763641544e-05\n",
            " MSE of Test data at current Epoch is:  0.20399890677191346\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 411 is:  0.0013125772676403006\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.6478764392905187e-05\n",
            " MSE of Test data at current Epoch is:  0.20405493262404226\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 412 is:  0.00130301647275635\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.5843702894331874e-05\n",
            " MSE of Test data at current Epoch is:  0.20425094806873684\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 413 is:  0.0013019201011115822\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.599351502728241e-05\n",
            " MSE of Test data at current Epoch is:  0.20418302276561723\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 414 is:  0.001291764762284733\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.555560686456375e-05\n",
            " MSE of Test data at current Epoch is:  0.20420996109572148\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 415 is:  0.0012899266102413915\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.5170040490628738e-05\n",
            " MSE of Test data at current Epoch is:  0.2042593876739798\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 416 is:  0.001283700118424626\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.5159790790778134e-05\n",
            " MSE of Test data at current Epoch is:  0.20425288661081462\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 417 is:  0.0012784859431170593\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.4879593306870657e-05\n",
            " MSE of Test data at current Epoch is:  0.20430847244900535\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 418 is:  0.001268692912454969\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.444994534296901e-05\n",
            " MSE of Test data at current Epoch is:  0.20438745326652372\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 419 is:  0.0012713988679315127\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.4338624753199406e-05\n",
            " MSE of Test data at current Epoch is:  0.20428433129288645\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 420 is:  0.0012599324982571233\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.3886112959707707e-05\n",
            " MSE of Test data at current Epoch is:  0.20441853647514446\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 421 is:  0.0012569799012794101\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.377822788388655e-05\n",
            " MSE of Test data at current Epoch is:  0.20441560294948985\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 422 is:  0.0012504670619846506\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.3432995737684575e-05\n",
            " MSE of Test data at current Epoch is:  0.20446064641010459\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 423 is:  0.0012454581999756615\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.3219638238054305e-05\n",
            " MSE of Test data at current Epoch is:  0.2044987049736064\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 424 is:  0.0012414195130601236\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.312294015834404e-05\n",
            " MSE of Test data at current Epoch is:  0.20450092976034182\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 425 is:  0.0012328936234245799\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.2810434004460022e-05\n",
            " MSE of Test data at current Epoch is:  0.20459692303455723\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 426 is:  0.0012337587345631902\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.266913357925187e-05\n",
            " MSE of Test data at current Epoch is:  0.2046544171620379\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 427 is:  0.0012249381400630123\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.2308055622963514e-05\n",
            " MSE of Test data at current Epoch is:  0.20457764783662516\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 428 is:  0.0012217930214349644\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.2218182693352247e-05\n",
            " MSE of Test data at current Epoch is:  0.20460228452409798\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 429 is:  0.0012119715993779319\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.1895274595662272e-05\n",
            " MSE of Test data at current Epoch is:  0.20471688421225348\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 430 is:  0.0012133793411355218\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.176321604518956e-05\n",
            " MSE of Test data at current Epoch is:  0.20470476936102563\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 431 is:  0.0012045804700112207\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.1394080934256376e-05\n",
            " MSE of Test data at current Epoch is:  0.20477157425849307\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 432 is:  0.0012015391359048479\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.1305444373822902e-05\n",
            " MSE of Test data at current Epoch is:  0.20479263452046628\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 433 is:  0.0011932260940050272\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.098286052523873e-05\n",
            " MSE of Test data at current Epoch is:  0.2049065964878181\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 434 is:  0.0011933898342591164\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.0875205793363727e-05\n",
            " MSE of Test data at current Epoch is:  0.20475250920448657\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 435 is:  0.0011870841238572232\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.071741542820889e-05\n",
            " MSE of Test data at current Epoch is:  0.2048260106123418\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 436 is:  0.001180686716185766\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.042769390067703e-05\n",
            " MSE of Test data at current Epoch is:  0.20497983941695164\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 437 is:  0.0011773617309237523\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.034433284373945e-05\n",
            " MSE of Test data at current Epoch is:  0.2049576642992531\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 438 is:  0.0011732245439581292\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  2.005288121631084e-05\n",
            " MSE of Test data at current Epoch is:  0.2048962165947971\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 439 is:  0.0011656346646926172\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.9782755051257094e-05\n",
            " MSE of Test data at current Epoch is:  0.20505405462873136\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 440 is:  0.0011649806815975249\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.9824141317153636e-05\n",
            " MSE of Test data at current Epoch is:  0.20502045463530294\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 441 is:  0.0011572756082819484\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.9455079498294774e-05\n",
            " MSE of Test data at current Epoch is:  0.20506473841803743\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 442 is:  0.0011547177824879306\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.9355073661287323e-05\n",
            " MSE of Test data at current Epoch is:  0.20501549304437133\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 443 is:  0.0011504835488759398\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.9297830314810493e-05\n",
            " MSE of Test data at current Epoch is:  0.20504836988481828\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 444 is:  0.0011460546891857238\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.90205728948406e-05\n",
            " MSE of Test data at current Epoch is:  0.20511254068039161\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 445 is:  0.0011397666846395945\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.8879067862827767e-05\n",
            " MSE of Test data at current Epoch is:  0.2051673862642165\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 446 is:  0.001139265977532487\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.8627542323261287e-05\n",
            " MSE of Test data at current Epoch is:  0.20520413778028676\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 447 is:  0.0011315623865923317\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.836168867243234e-05\n",
            " MSE of Test data at current Epoch is:  0.20523747906674364\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 448 is:  0.0011282970541844723\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.8235306181051356e-05\n",
            " MSE of Test data at current Epoch is:  0.20527609539049135\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 449 is:  0.0011259415156351837\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.8296541140862744e-05\n",
            " MSE of Test data at current Epoch is:  0.20514171858903704\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 450 is:  0.001119818136529014\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.793473843346137e-05\n",
            " MSE of Test data at current Epoch is:  0.2053093075321951\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 451 is:  0.0011157438814091809\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.7762825420007715e-05\n",
            " MSE of Test data at current Epoch is:  0.2053737999255117\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 452 is:  0.0011136805023015822\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.7690793380788765e-05\n",
            " MSE of Test data at current Epoch is:  0.20531828082763753\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 453 is:  0.001105574011786926\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.7486162203841577e-05\n",
            " MSE of Test data at current Epoch is:  0.20537808221500928\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 454 is:  0.001105084388921677\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.7374586910450314e-05\n",
            " MSE of Test data at current Epoch is:  0.20547857810861572\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 455 is:  0.0010998629561058371\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.7228465269195755e-05\n",
            " MSE of Test data at current Epoch is:  0.20536217053673422\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 456 is:  0.001096199159278757\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.7038536679912108e-05\n",
            " MSE of Test data at current Epoch is:  0.20545361721436423\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 457 is:  0.0010890035791811421\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.6859237856744848e-05\n",
            " MSE of Test data at current Epoch is:  0.20551032373147884\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 458 is:  0.0010890977596957506\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.683242900687462e-05\n",
            " MSE of Test data at current Epoch is:  0.20541528743334517\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 459 is:  0.001083544389858018\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.6671800404590497e-05\n",
            " MSE of Test data at current Epoch is:  0.20549065983004386\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 460 is:  0.0010799455608006753\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.6453051237177265e-05\n",
            " MSE of Test data at current Epoch is:  0.20562871795555265\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 461 is:  0.0010769963317238858\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.6407389033872866e-05\n",
            " MSE of Test data at current Epoch is:  0.20551784894861252\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 462 is:  0.0010721053617860144\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.6160827218296918e-05\n",
            " MSE of Test data at current Epoch is:  0.2056187442053987\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 463 is:  0.0010662594690782497\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.605056153933745e-05\n",
            " MSE of Test data at current Epoch is:  0.2056410512970358\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 464 is:  0.0010653944245118349\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.5955544507673687e-05\n",
            " MSE of Test data at current Epoch is:  0.2057219193276829\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 465 is:  0.0010599332062616897\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.5766803015879643e-05\n",
            " MSE of Test data at current Epoch is:  0.20564506731448845\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 466 is:  0.0010577320104066248\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.5655870074615314e-05\n",
            " MSE of Test data at current Epoch is:  0.20571960064333783\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 467 is:  0.0010527626492450558\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.5657984497829928e-05\n",
            " MSE of Test data at current Epoch is:  0.20572627567415536\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 468 is:  0.0010498429683363452\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.53495248414524e-05\n",
            " MSE of Test data at current Epoch is:  0.2057648619149687\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 469 is:  0.001046250488294233\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.532110956148301e-05\n",
            " MSE of Test data at current Epoch is:  0.20573037758460072\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 470 is:  0.001043140733557483\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.5222718949738758e-05\n",
            " MSE of Test data at current Epoch is:  0.20577190416665925\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 471 is:  0.0010387894652553642\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.5100175687140094e-05\n",
            " MSE of Test data at current Epoch is:  0.20577271305805298\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 472 is:  0.001035021556787077\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.4930095918867273e-05\n",
            " MSE of Test data at current Epoch is:  0.20586702683342573\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 473 is:  0.0010306774370334724\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.4837772894523046e-05\n",
            " MSE of Test data at current Epoch is:  0.20591861003867512\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 474 is:  0.001028645381969216\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.4689821671645592e-05\n",
            " MSE of Test data at current Epoch is:  0.20584330060276304\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 475 is:  0.0010238118075918579\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.4591327826660064e-05\n",
            " MSE of Test data at current Epoch is:  0.20590407450964876\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 476 is:  0.0010221415014344945\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.4416124254237157e-05\n",
            " MSE of Test data at current Epoch is:  0.20593588378009042\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 477 is:  0.0010172560192530191\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.436747468126026e-05\n",
            " MSE of Test data at current Epoch is:  0.20594736543289885\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 478 is:  0.001014417321903423\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.4260151865370911e-05\n",
            " MSE of Test data at current Epoch is:  0.20596878969083585\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 479 is:  0.0010095117432982214\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.4145764691598699e-05\n",
            " MSE of Test data at current Epoch is:  0.20595791580317754\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 480 is:  0.0010092951562547456\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.4114926540313744e-05\n",
            " MSE of Test data at current Epoch is:  0.205965380590173\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 481 is:  0.0010035126636367849\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.3943787216682014e-05\n",
            " MSE of Test data at current Epoch is:  0.20601843774663992\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 482 is:  0.0010018172075637378\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.3798958335178091e-05\n",
            " MSE of Test data at current Epoch is:  0.20604300211833276\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 483 is:  0.0009957569096040039\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.3751444153563792e-05\n",
            " MSE of Test data at current Epoch is:  0.2060559613480739\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 484 is:  0.0009938149233151923\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.351394464020554e-05\n",
            " MSE of Test data at current Epoch is:  0.20616678767349847\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 485 is:  0.000990314942590533\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.3499124522298267e-05\n",
            " MSE of Test data at current Epoch is:  0.2060843200035253\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 486 is:  0.0009880950696724373\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.3456790971964809e-05\n",
            " MSE of Test data at current Epoch is:  0.20611933329471202\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 487 is:  0.000983889090609995\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.3315961322439596e-05\n",
            " MSE of Test data at current Epoch is:  0.20619760205586649\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 488 is:  0.0009798107616278621\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.3237423384527258e-05\n",
            " MSE of Test data at current Epoch is:  0.2061191567381333\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 489 is:  0.0009784011309803527\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.3111620053571491e-05\n",
            " MSE of Test data at current Epoch is:  0.2061661167187354\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 490 is:  0.0009727097543113367\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.3000938292222879e-05\n",
            " MSE of Test data at current Epoch is:  0.20625814203444798\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 491 is:  0.0009714394579976343\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.289375990628451e-05\n",
            " MSE of Test data at current Epoch is:  0.2062262260057396\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 492 is:  0.0009661689774422613\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.2852971724368364e-05\n",
            " MSE of Test data at current Epoch is:  0.20626027190474724\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 493 is:  0.0009651328838032112\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.267622965404809e-05\n",
            " MSE of Test data at current Epoch is:  0.20633821733118\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 494 is:  0.0009610212925321248\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.2673749519040797e-05\n",
            " MSE of Test data at current Epoch is:  0.20625552538634714\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 495 is:  0.0009586917190171911\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.2554035357801226e-05\n",
            " MSE of Test data at current Epoch is:  0.20629735103253524\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 496 is:  0.0009550772922992383\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.241356071573548e-05\n",
            " MSE of Test data at current Epoch is:  0.20639399290440222\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 497 is:  0.0009511877453597145\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.22935798912043e-05\n",
            " MSE of Test data at current Epoch is:  0.20646356807521174\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 498 is:  0.0009492379772267179\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.2334891134469426e-05\n",
            " MSE of Test data at current Epoch is:  0.20630369368792412\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 499 is:  0.0009463778461651193\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.2195983335508217e-05\n",
            " MSE of Test data at current Epoch is:  0.206398736986164\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 500 is:  0.0009422982532045767\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.2123119282400212e-05\n",
            " MSE of Test data at current Epoch is:  0.20647319094336852\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 501 is:  0.0009398620370238107\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.1974981264429462e-05\n",
            " MSE of Test data at current Epoch is:  0.2064402891329097\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 502 is:  0.0009366179525769651\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.195548997423961e-05\n",
            " MSE of Test data at current Epoch is:  0.20647711150844977\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 503 is:  0.0009341438615051238\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.185275979019521e-05\n",
            " MSE of Test data at current Epoch is:  0.2064156348329882\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 504 is:  0.0009311709706993489\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.1821640098587415e-05\n",
            " MSE of Test data at current Epoch is:  0.2065002280860446\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 505 is:  0.000927883842686007\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.1706364410054538e-05\n",
            " MSE of Test data at current Epoch is:  0.20649890715511865\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 506 is:  0.0009253968679399498\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.1587447989958712e-05\n",
            " MSE of Test data at current Epoch is:  0.20659903009301642\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 507 is:  0.0009224288818647834\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.1514511287450564e-05\n",
            " MSE of Test data at current Epoch is:  0.20654287551601097\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 508 is:  0.0009195743028537561\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.144499061640436e-05\n",
            " MSE of Test data at current Epoch is:  0.2065848432170712\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 509 is:  0.0009164608678785891\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.1451049037540392e-05\n",
            " MSE of Test data at current Epoch is:  0.20657440065413415\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 510 is:  0.0009146467639528665\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.1308995123217032e-05\n",
            " MSE of Test data at current Epoch is:  0.20655833028219298\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 511 is:  0.0009085930086770757\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.78\n",
            " MSE of Training data at current Epoch is:  1.1164980854475027e-05\n",
            " MSE of Test data at current Epoch is:  0.2066671822199399\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  11.0\n",
            "\n",
            "*Cost for Training data at Epoch: 512 is:  0.0009087855959925408\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.113080501772882e-05\n",
            " MSE of Test data at current Epoch is:  0.2067096671815942\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 513 is:  0.0009047341450230107\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.1036876975485508e-05\n",
            " MSE of Test data at current Epoch is:  0.20663814932844585\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 514 is:  0.0009029585101138518\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.1009907913056836e-05\n",
            " MSE of Test data at current Epoch is:  0.20667808157832962\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 515 is:  0.0009002458139813961\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.087999345601339e-05\n",
            " MSE of Test data at current Epoch is:  0.20670607153000592\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 516 is:  0.0008968209396254469\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.0858327865963107e-05\n",
            " MSE of Test data at current Epoch is:  0.20670287245671543\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 517 is:  0.0008948310779474744\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.0757068552483459e-05\n",
            " MSE of Test data at current Epoch is:  0.2067492230154357\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 518 is:  0.000891277567017483\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.0667260967635801e-05\n",
            " MSE of Test data at current Epoch is:  0.20672362347898543\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 519 is:  0.0008882581316166158\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.0706861831075652e-05\n",
            " MSE of Test data at current Epoch is:  0.20674742530941528\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 520 is:  0.0008864576298742308\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.0551836837626397e-05\n",
            " MSE of Test data at current Epoch is:  0.20673660494409998\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 521 is:  0.0008822410000105572\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.0457687137768887e-05\n",
            " MSE of Test data at current Epoch is:  0.20685666559697313\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 522 is:  0.0008813641404179188\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.041516404807701e-05\n",
            " MSE of Test data at current Epoch is:  0.20678974802115171\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 523 is:  0.0008767024509002949\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.0339640119575712e-05\n",
            " MSE of Test data at current Epoch is:  0.2068455356245192\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 524 is:  0.0008756402324568627\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.0286042923817296e-05\n",
            " MSE of Test data at current Epoch is:  0.20690936292224923\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 525 is:  0.0008725771321186139\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.0215196072901668e-05\n",
            " MSE of Test data at current Epoch is:  0.20685808346076726\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 526 is:  0.00087061448097507\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.0154742597421199e-05\n",
            " MSE of Test data at current Epoch is:  0.20685736634271887\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 527 is:  0.0008687536981090187\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.0116250269082543e-05\n",
            " MSE of Test data at current Epoch is:  0.20683814847243473\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 528 is:  0.0008646914511088114\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.0073414273462533e-05\n",
            " MSE of Test data at current Epoch is:  0.2068852908237903\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 529 is:  0.0008628772853067081\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  9.939545419919362e-06\n",
            " MSE of Test data at current Epoch is:  0.20696485170151024\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 530 is:  0.0008587425880182641\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  9.872882066760117e-06\n",
            " MSE of Test data at current Epoch is:  0.20693422351711024\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 531 is:  0.0008586697494788498\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  9.891826309144187e-06\n",
            " MSE of Test data at current Epoch is:  0.2069072944449822\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 532 is:  0.0008559253597051908\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  9.753469969117948e-06\n",
            " MSE of Test data at current Epoch is:  0.20696475272566545\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 533 is:  0.0008516536475438362\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  9.728633039228358e-06\n",
            " MSE of Test data at current Epoch is:  0.20696537896261366\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 534 is:  0.0008515858475652935\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  9.727995714548428e-06\n",
            " MSE of Test data at current Epoch is:  0.20697332493104284\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 535 is:  0.0008467770236292294\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  9.545498630769137e-06\n",
            " MSE of Test data at current Epoch is:  0.2070530061029639\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 536 is:  0.0008456415501642693\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  9.501572798970986e-06\n",
            " MSE of Test data at current Epoch is:  0.20704729139101552\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 537 is:  0.0008421051608622255\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  9.479224589549932e-06\n",
            " MSE of Test data at current Epoch is:  0.20706671074481933\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 538 is:  0.0008404716160457895\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  9.40365233436333e-06\n",
            " MSE of Test data at current Epoch is:  0.20703455515456365\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 539 is:  0.0008384422874303841\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  9.368195549527103e-06\n",
            " MSE of Test data at current Epoch is:  0.20706364816981082\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 540 is:  0.0008342983813277797\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  9.295607247370138e-06\n",
            " MSE of Test data at current Epoch is:  0.20709065855997388\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 541 is:  0.0008343055919641749\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  9.239130959292465e-06\n",
            " MSE of Test data at current Epoch is:  0.20716460960961453\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 542 is:  0.0008296763548103147\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  9.18123629716166e-06\n",
            " MSE of Test data at current Epoch is:  0.2070892761141686\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 543 is:  0.000828130638837695\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  9.106742604686987e-06\n",
            " MSE of Test data at current Epoch is:  0.207195029185244\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 544 is:  0.0008274166188733147\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  9.101204739479397e-06\n",
            " MSE of Test data at current Epoch is:  0.2071442367724346\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 545 is:  0.0008221428466574013\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  9.00807858409897e-06\n",
            " MSE of Test data at current Epoch is:  0.20717265268388255\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 546 is:  0.0008210838367121908\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.96969913381883e-06\n",
            " MSE of Test data at current Epoch is:  0.2072145991949377\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 547 is:  0.0008184297068577913\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.920760894073257e-06\n",
            " MSE of Test data at current Epoch is:  0.20719057852136982\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 548 is:  0.0008163687529207734\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.857983561618049e-06\n",
            " MSE of Test data at current Epoch is:  0.2072327660416007\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 549 is:  0.0008141312540678305\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.85359367110693e-06\n",
            " MSE of Test data at current Epoch is:  0.20723790653388574\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 550 is:  0.0008121579379913859\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.738858603008397e-06\n",
            " MSE of Test data at current Epoch is:  0.20721632578128893\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 551 is:  0.000809720550431932\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.685473493617692e-06\n",
            " MSE of Test data at current Epoch is:  0.20733047121184786\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 552 is:  0.000807024353084355\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.62277813771613e-06\n",
            " MSE of Test data at current Epoch is:  0.20725717755470194\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 553 is:  0.0008058794033684371\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.620666590208306e-06\n",
            " MSE of Test data at current Epoch is:  0.20729250991706905\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 554 is:  0.0008018770039187654\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.560443846446612e-06\n",
            " MSE of Test data at current Epoch is:  0.20735586691378835\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 555 is:  0.0008011780075389773\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.461370917463838e-06\n",
            " MSE of Test data at current Epoch is:  0.20733040912809236\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 556 is:  0.0007990656008699669\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.468497361228304e-06\n",
            " MSE of Test data at current Epoch is:  0.20733788203325446\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 557 is:  0.000795942513824384\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.433383319351706e-06\n",
            " MSE of Test data at current Epoch is:  0.2073207337800597\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 558 is:  0.0007937959394498607\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.335875213741738e-06\n",
            " MSE of Test data at current Epoch is:  0.207398340984023\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 559 is:  0.0007909870989319695\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.318005631266235e-06\n",
            " MSE of Test data at current Epoch is:  0.2073516407329952\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 560 is:  0.0007896056553815607\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.258867364041636e-06\n",
            " MSE of Test data at current Epoch is:  0.20739983585262411\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 561 is:  0.0007875009109490455\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.236538421149108e-06\n",
            " MSE of Test data at current Epoch is:  0.20737159896618632\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 562 is:  0.0007857679838450623\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.170433044812218e-06\n",
            " MSE of Test data at current Epoch is:  0.20739705858668764\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 563 is:  0.0007818755059653864\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.105734203017295e-06\n",
            " MSE of Test data at current Epoch is:  0.20751060124104415\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 564 is:  0.0007815345533876563\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.05111731313395e-06\n",
            " MSE of Test data at current Epoch is:  0.20742661858603345\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 565 is:  0.0007775419296475106\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.025144601102238e-06\n",
            " MSE of Test data at current Epoch is:  0.20749667635269906\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 566 is:  0.0007777181072738559\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  8.00275040982927e-06\n",
            " MSE of Test data at current Epoch is:  0.2074421399151357\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 567 is:  0.0007749362084571592\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.921196577861362e-06\n",
            " MSE of Test data at current Epoch is:  0.20754395631328632\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 568 is:  0.000772884647654403\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.87212065406255e-06\n",
            " MSE of Test data at current Epoch is:  0.2074904551539541\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 569 is:  0.0007705689852133503\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.80520470780655e-06\n",
            " MSE of Test data at current Epoch is:  0.20755876199162313\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 570 is:  0.0007678774997996089\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.803357393505212e-06\n",
            " MSE of Test data at current Epoch is:  0.207535978965238\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 571 is:  0.0007668163052355318\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.754898182638735e-06\n",
            " MSE of Test data at current Epoch is:  0.20755530570558492\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 572 is:  0.0007634340413111503\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.717982430077015e-06\n",
            " MSE of Test data at current Epoch is:  0.20758574544008557\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 573 is:  0.0007629726190955489\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.628269292152591e-06\n",
            " MSE of Test data at current Epoch is:  0.20759130946273094\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 574 is:  0.0007596552607163303\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.621282594514126e-06\n",
            " MSE of Test data at current Epoch is:  0.20760669677875487\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 575 is:  0.0007594139803113697\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.619596759084964e-06\n",
            " MSE of Test data at current Epoch is:  0.2075391911095483\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 576 is:  0.0007561285314238716\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.558466017864151e-06\n",
            " MSE of Test data at current Epoch is:  0.2076265548360321\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 577 is:  0.000754235761227956\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.480261203089491e-06\n",
            " MSE of Test data at current Epoch is:  0.20765716894717898\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 578 is:  0.0007536572796620328\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.4686710043621375e-06\n",
            " MSE of Test data at current Epoch is:  0.207603167333628\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 579 is:  0.0007493744887190864\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.415800923217064e-06\n",
            " MSE of Test data at current Epoch is:  0.2076829895896054\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 580 is:  0.0007484637030948161\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.3442157972110505e-06\n",
            " MSE of Test data at current Epoch is:  0.20766759468449383\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 581 is:  0.0007465495476418893\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.375183758683211e-06\n",
            " MSE of Test data at current Epoch is:  0.20767724820781225\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 582 is:  0.0007451847599722469\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.300990865537064e-06\n",
            " MSE of Test data at current Epoch is:  0.20767081394431222\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 583 is:  0.0007411908150249189\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.221904067047303e-06\n",
            " MSE of Test data at current Epoch is:  0.20775084524423013\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 584 is:  0.0007413333592293168\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.2040010742578125e-06\n",
            " MSE of Test data at current Epoch is:  0.2077311502347679\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 585 is:  0.000739499053401743\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.166342747535206e-06\n",
            " MSE of Test data at current Epoch is:  0.20775924591666534\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 586 is:  0.0007359424981670465\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.144716801800204e-06\n",
            " MSE of Test data at current Epoch is:  0.20773464815116174\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 587 is:  0.0007354991903433394\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.093552407005933e-06\n",
            " MSE of Test data at current Epoch is:  0.20773524122496959\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 588 is:  0.0007336612258294487\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.054205722602664e-06\n",
            " MSE of Test data at current Epoch is:  0.20774045208464967\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 589 is:  0.0007309411201034128\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  7.053905833412452e-06\n",
            " MSE of Test data at current Epoch is:  0.20779591785947826\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 590 is:  0.0007295562222773539\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.9906055849189464e-06\n",
            " MSE of Test data at current Epoch is:  0.20781116592130847\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 591 is:  0.0007264371117724979\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.940395599030692e-06\n",
            " MSE of Test data at current Epoch is:  0.20780804537628006\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 592 is:  0.0007255765713500722\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.9018486955918455e-06\n",
            " MSE of Test data at current Epoch is:  0.20784066424754877\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 593 is:  0.0007236279353840568\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.852023669191967e-06\n",
            " MSE of Test data at current Epoch is:  0.2078283451967746\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 594 is:  0.0007209297554055535\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.84018010729472e-06\n",
            " MSE of Test data at current Epoch is:  0.20785419417229187\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 595 is:  0.0007205301874714357\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.8122105739891285e-06\n",
            " MSE of Test data at current Epoch is:  0.20785086121454469\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 596 is:  0.0007182963491637315\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.771742159287563e-06\n",
            " MSE of Test data at current Epoch is:  0.20791169648131355\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 597 is:  0.0007158622388981253\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.726493704451949e-06\n",
            " MSE of Test data at current Epoch is:  0.20790291381681564\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 598 is:  0.0007143952884494405\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.670028067497325e-06\n",
            " MSE of Test data at current Epoch is:  0.20794236901985685\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 599 is:  0.0007124582871214834\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.63762750445101e-06\n",
            " MSE of Test data at current Epoch is:  0.20791346170259364\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 600 is:  0.0007095774935718455\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.615183333937102e-06\n",
            " MSE of Test data at current Epoch is:  0.20793845329885327\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 601 is:  0.0007090624780838607\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.591914859899373e-06\n",
            " MSE of Test data at current Epoch is:  0.20791973577180575\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 602 is:  0.0007073201489798589\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.554105213602216e-06\n",
            " MSE of Test data at current Epoch is:  0.20796560056841773\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 603 is:  0.0007048715924453811\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.532057586556661e-06\n",
            " MSE of Test data at current Epoch is:  0.2079410350831823\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 604 is:  0.0007038740852416706\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.48664152351731e-06\n",
            " MSE of Test data at current Epoch is:  0.207974554108933\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 605 is:  0.0007019725353406266\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.456257389416722e-06\n",
            " MSE of Test data at current Epoch is:  0.20797509451547322\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 606 is:  0.0006998413412057406\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.434702294697559e-06\n",
            " MSE of Test data at current Epoch is:  0.2080019379436021\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 607 is:  0.0006990509407594923\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.390340230050803e-06\n",
            " MSE of Test data at current Epoch is:  0.20796315660779477\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 608 is:  0.0006961117529978953\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.347573019262995e-06\n",
            " MSE of Test data at current Epoch is:  0.20803900340273848\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 609 is:  0.000694330876075269\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.320420833249317e-06\n",
            " MSE of Test data at current Epoch is:  0.20799264021591465\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 610 is:  0.000693295040956582\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.294254729072168e-06\n",
            " MSE of Test data at current Epoch is:  0.208050255317855\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 611 is:  0.0006917841204729501\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.284242624377954e-06\n",
            " MSE of Test data at current Epoch is:  0.20800998802978027\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 612 is:  0.0006900947872937068\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.227965734735485e-06\n",
            " MSE of Test data at current Epoch is:  0.20805867110051302\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 613 is:  0.0006880360737662476\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.195292900667676e-06\n",
            " MSE of Test data at current Epoch is:  0.2080551573165151\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 614 is:  0.0006861775768195191\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.1873113031887605e-06\n",
            " MSE of Test data at current Epoch is:  0.2080940029563069\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 615 is:  0.0006854781145086628\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.13917499218831e-06\n",
            " MSE of Test data at current Epoch is:  0.2080324700379604\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 616 is:  0.0006822979324300392\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.0971145659198175e-06\n",
            " MSE of Test data at current Epoch is:  0.20810845780697873\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 617 is:  0.000682496904821605\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.0890192817940015e-06\n",
            " MSE of Test data at current Epoch is:  0.20807102968540603\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 618 is:  0.0006793314480001019\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.049626668518354e-06\n",
            " MSE of Test data at current Epoch is:  0.20813960547493962\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 619 is:  0.0006779815037884807\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  6.001342561599616e-06\n",
            " MSE of Test data at current Epoch is:  0.20812769082391724\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 620 is:  0.0006765902458014661\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.999170553098594e-06\n",
            " MSE of Test data at current Epoch is:  0.20815867320926632\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 621 is:  0.0006750506684613668\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.945784098590245e-06\n",
            " MSE of Test data at current Epoch is:  0.20815006214508192\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 622 is:  0.0006734294184545667\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.917646112199356e-06\n",
            " MSE of Test data at current Epoch is:  0.20815848166782414\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 623 is:  0.00067230637205946\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.901353645566366e-06\n",
            " MSE of Test data at current Epoch is:  0.20815144496764543\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 624 is:  0.000670051755205435\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.869596733080611e-06\n",
            " MSE of Test data at current Epoch is:  0.2081641398477829\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 625 is:  0.0006681420344665991\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.825829038484118e-06\n",
            " MSE of Test data at current Epoch is:  0.20816822602934196\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 626 is:  0.0006678007557119608\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.828807951934356e-06\n",
            " MSE of Test data at current Epoch is:  0.20820040291805167\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 627 is:  0.0006656590011634321\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.776409802996881e-06\n",
            " MSE of Test data at current Epoch is:  0.20816868813519807\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 628 is:  0.0006633176883833465\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.7446673406209335e-06\n",
            " MSE of Test data at current Epoch is:  0.20825529585204816\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 629 is:  0.0006624064391668364\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.7305900336346475e-06\n",
            " MSE of Test data at current Epoch is:  0.20821642083641845\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 630 is:  0.0006604353763139147\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.69642453412702e-06\n",
            " MSE of Test data at current Epoch is:  0.20825220829266847\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 631 is:  0.0006585604723203685\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.671608076310062e-06\n",
            " MSE of Test data at current Epoch is:  0.2082324903112059\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 632 is:  0.0006581848731154416\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.667847512396297e-06\n",
            " MSE of Test data at current Epoch is:  0.2082407827899617\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 633 is:  0.000655447684182146\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.616303135363339e-06\n",
            " MSE of Test data at current Epoch is:  0.20825580717307424\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 634 is:  0.0006545017327958079\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.588094390421793e-06\n",
            " MSE of Test data at current Epoch is:  0.20828951002187704\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 635 is:  0.0006532918490671608\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.590598421060822e-06\n",
            " MSE of Test data at current Epoch is:  0.2082349147253356\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 636 is:  0.0006517605210975833\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.547092001207947e-06\n",
            " MSE of Test data at current Epoch is:  0.20829392534648886\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 637 is:  0.0006497839570977023\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.4889461178225355e-06\n",
            " MSE of Test data at current Epoch is:  0.208300808621004\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 638 is:  0.000648376780494625\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.511611221002685e-06\n",
            " MSE of Test data at current Epoch is:  0.20828808692066106\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 639 is:  0.0006469367212408412\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.45317979447079e-06\n",
            " MSE of Test data at current Epoch is:  0.20830905427538718\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 640 is:  0.0006457664202911286\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.448585248680193e-06\n",
            " MSE of Test data at current Epoch is:  0.20834979234492662\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 641 is:  0.0006437880145282727\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.412008088730009e-06\n",
            " MSE of Test data at current Epoch is:  0.20833603685157367\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 642 is:  0.0006426198717803826\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.3758561158104545e-06\n",
            " MSE of Test data at current Epoch is:  0.2083750014845354\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 643 is:  0.0006409242504648156\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.368649392285475e-06\n",
            " MSE of Test data at current Epoch is:  0.2083468616503426\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 644 is:  0.0006394811732837304\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.328378496381747e-06\n",
            " MSE of Test data at current Epoch is:  0.20837610181619914\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 645 is:  0.0006381706349682152\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.322293290309416e-06\n",
            " MSE of Test data at current Epoch is:  0.20834079767678057\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 646 is:  0.0006373128237583519\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.305462151464015e-06\n",
            " MSE of Test data at current Epoch is:  0.20838763580787606\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 647 is:  0.0006350861243228157\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.267931041428247e-06\n",
            " MSE of Test data at current Epoch is:  0.20835536725591236\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 648 is:  0.0006343445680182409\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.244631764643942e-06\n",
            " MSE of Test data at current Epoch is:  0.20839021234732838\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 649 is:  0.0006323764384835097\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.2327261591931926e-06\n",
            " MSE of Test data at current Epoch is:  0.20838852719123124\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 650 is:  0.0006309792410207339\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.1964276135103365e-06\n",
            " MSE of Test data at current Epoch is:  0.20842568750032534\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 651 is:  0.0006296172658848426\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.1596160965849115e-06\n",
            " MSE of Test data at current Epoch is:  0.20840755533893304\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 652 is:  0.0006291599357777935\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.159649756146246e-06\n",
            " MSE of Test data at current Epoch is:  0.20841637415571554\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 653 is:  0.0006274292554998022\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.119388186739469e-06\n",
            " MSE of Test data at current Epoch is:  0.20842783863530945\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 654 is:  0.0006253149554938659\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.084621955236249e-06\n",
            " MSE of Test data at current Epoch is:  0.20847840932654144\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 655 is:  0.0006241393459304371\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.0850200922180755e-06\n",
            " MSE of Test data at current Epoch is:  0.20840040298118148\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 656 is:  0.0006224976004859682\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.029613558536579e-06\n",
            " MSE of Test data at current Epoch is:  0.20850432792488632\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 657 is:  0.0006217090930866922\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.036583798261044e-06\n",
            " MSE of Test data at current Epoch is:  0.20842649539016364\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 658 is:  0.0006210284521078011\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  5.0309105323196e-06\n",
            " MSE of Test data at current Epoch is:  0.208487521287206\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 659 is:  0.0006185459136799931\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.98321042634169e-06\n",
            " MSE of Test data at current Epoch is:  0.20847106033030088\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 660 is:  0.0006173743854229396\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.956914935457969e-06\n",
            " MSE of Test data at current Epoch is:  0.20852501633819948\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 661 is:  0.0006156810157731933\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.9320917515802345e-06\n",
            " MSE of Test data at current Epoch is:  0.20848787325068835\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 662 is:  0.0006145243624550376\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.9222588266290895e-06\n",
            " MSE of Test data at current Epoch is:  0.2085235391830285\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 663 is:  0.0006133333370332034\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.90693866613238e-06\n",
            " MSE of Test data at current Epoch is:  0.20851047241261225\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 664 is:  0.0006117883539323115\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.854615083762881e-06\n",
            " MSE of Test data at current Epoch is:  0.208577196272855\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 665 is:  0.0006107841220905863\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.855452866370464e-06\n",
            " MSE of Test data at current Epoch is:  0.20851011177631132\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 666 is:  0.0006093289233798757\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.833402823532452e-06\n",
            " MSE of Test data at current Epoch is:  0.20857147057456146\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 667 is:  0.0006082523298244561\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.8124450799726806e-06\n",
            " MSE of Test data at current Epoch is:  0.2085235240163228\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 668 is:  0.0006061641258173891\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.783478311000233e-06\n",
            " MSE of Test data at current Epoch is:  0.20858610641988884\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 669 is:  0.0006053460453277523\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.775267568821037e-06\n",
            " MSE of Test data at current Epoch is:  0.20855775497481366\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 670 is:  0.0006044667634021764\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.751626527702987e-06\n",
            " MSE of Test data at current Epoch is:  0.20859812806867045\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 671 is:  0.000602632534831105\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.716389507019476e-06\n",
            " MSE of Test data at current Epoch is:  0.20856912371486583\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 672 is:  0.0006011312889490208\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.693370669936892e-06\n",
            " MSE of Test data at current Epoch is:  0.20865203518519032\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 673 is:  0.0006000551266162833\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.664052379289789e-06\n",
            " MSE of Test data at current Epoch is:  0.20861373455487872\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 674 is:  0.0005984220424252494\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.6744772352386376e-06\n",
            " MSE of Test data at current Epoch is:  0.20863138885913185\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 675 is:  0.0005984383362256402\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.650287972779231e-06\n",
            " MSE of Test data at current Epoch is:  0.20859116408325395\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 676 is:  0.0005958408243458374\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.616201141347453e-06\n",
            " MSE of Test data at current Epoch is:  0.20865906254142608\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 677 is:  0.0005954029772062927\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.608906535918191e-06\n",
            " MSE of Test data at current Epoch is:  0.20860639887144405\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 678 is:  0.000593475987474096\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.584452752880061e-06\n",
            " MSE of Test data at current Epoch is:  0.20865366499422028\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 679 is:  0.0005929680692317143\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.5656068048406815e-06\n",
            " MSE of Test data at current Epoch is:  0.20861445362311376\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 680 is:  0.0005914824093912272\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.54470742219677e-06\n",
            " MSE of Test data at current Epoch is:  0.20869128560495737\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 681 is:  0.0005899642693955508\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.510677274912581e-06\n",
            " MSE of Test data at current Epoch is:  0.20867182117493907\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 682 is:  0.0005892341710175108\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.502416885104444e-06\n",
            " MSE of Test data at current Epoch is:  0.2086796043788987\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 683 is:  0.0005872268598693622\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.4904987717449955e-06\n",
            " MSE of Test data at current Epoch is:  0.20867635512275645\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 684 is:  0.0005864970537591561\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.455002437415975e-06\n",
            " MSE of Test data at current Epoch is:  0.20872252149219084\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 685 is:  0.0005853472320885834\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.444352793925945e-06\n",
            " MSE of Test data at current Epoch is:  0.20869167449234688\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 686 is:  0.0005840916687813726\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.415068057342253e-06\n",
            " MSE of Test data at current Epoch is:  0.2087415297698257\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 687 is:  0.0005828475047304576\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.421466677524491e-06\n",
            " MSE of Test data at current Epoch is:  0.20866893660531333\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 688 is:  0.0005816472530218884\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.379934640543552e-06\n",
            " MSE of Test data at current Epoch is:  0.20877382343783782\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 689 is:  0.0005803339020159722\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.358517354945706e-06\n",
            " MSE of Test data at current Epoch is:  0.20873175496968163\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 690 is:  0.0005791691626347084\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.348185843295878e-06\n",
            " MSE of Test data at current Epoch is:  0.2087669786534204\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 691 is:  0.0005774423557822975\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.335964393961456e-06\n",
            " MSE of Test data at current Epoch is:  0.20873931258316344\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 692 is:  0.0005767347066024691\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.309452987538363e-06\n",
            " MSE of Test data at current Epoch is:  0.2087824237627692\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 693 is:  0.0005755035637355731\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.303157629708421e-06\n",
            " MSE of Test data at current Epoch is:  0.20872762163756714\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 694 is:  0.0005741773863034737\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.276950099660152e-06\n",
            " MSE of Test data at current Epoch is:  0.20877729846354723\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 695 is:  0.0005734381444220211\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.255331493558938e-06\n",
            " MSE of Test data at current Epoch is:  0.20876920046116124\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 696 is:  0.000571847150163166\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.2430251756302715e-06\n",
            " MSE of Test data at current Epoch is:  0.20880589089356452\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 697 is:  0.0005707477523867593\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.220753000280219e-06\n",
            " MSE of Test data at current Epoch is:  0.20880655795085445\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 698 is:  0.0005697701382534349\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.211166923562783e-06\n",
            " MSE of Test data at current Epoch is:  0.20882253426599043\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 699 is:  0.00056859781838154\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.193492728070685e-06\n",
            " MSE of Test data at current Epoch is:  0.20883331855885467\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 700 is:  0.0005666668151017459\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.15680336772172e-06\n",
            " MSE of Test data at current Epoch is:  0.20881805821116867\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 701 is:  0.0005665086098149518\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.1537468830036495e-06\n",
            " MSE of Test data at current Epoch is:  0.20885858235280685\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 702 is:  0.0005647170397299472\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.12892422823873e-06\n",
            " MSE of Test data at current Epoch is:  0.20885228374235418\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 703 is:  0.0005640923625128018\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.124508018547398e-06\n",
            " MSE of Test data at current Epoch is:  0.20885387482740958\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 704 is:  0.000562741176474694\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.1120356212653374e-06\n",
            " MSE of Test data at current Epoch is:  0.2088406999923848\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 705 is:  0.0005616084015801535\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.0784315822788045e-06\n",
            " MSE of Test data at current Epoch is:  0.2088795322042368\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 706 is:  0.000560100098397862\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.060696676768255e-06\n",
            " MSE of Test data at current Epoch is:  0.20886425744346976\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 707 is:  0.0005592312797409388\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.05335979940696e-06\n",
            " MSE of Test data at current Epoch is:  0.20889402774604293\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 708 is:  0.0005579915693148511\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.0434365105009164e-06\n",
            " MSE of Test data at current Epoch is:  0.20884163025961666\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 709 is:  0.0005569954619743402\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.016482091732238e-06\n",
            " MSE of Test data at current Epoch is:  0.20891768331236185\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 710 is:  0.0005562091643837264\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  4.002078595825567e-06\n",
            " MSE of Test data at current Epoch is:  0.20887349004906677\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 711 is:  0.000555195980728783\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.979402524705832e-06\n",
            " MSE of Test data at current Epoch is:  0.20892167970333517\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 712 is:  0.0005531739332170838\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.955894953817021e-06\n",
            " MSE of Test data at current Epoch is:  0.20893295045840635\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 713 is:  0.0005528324580865413\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.956335778393042e-06\n",
            " MSE of Test data at current Epoch is:  0.20892675326746052\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 714 is:  0.0005518430353612212\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.9392501913912004e-06\n",
            " MSE of Test data at current Epoch is:  0.2089045864630067\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 715 is:  0.0005503099852027454\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.9098808931574665e-06\n",
            " MSE of Test data at current Epoch is:  0.20897321210531505\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 716 is:  0.0005492540841257477\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.915605688225094e-06\n",
            " MSE of Test data at current Epoch is:  0.20890258296447298\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 717 is:  0.0005487107462326081\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.895152061066997e-06\n",
            " MSE of Test data at current Epoch is:  0.20894241500852065\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 718 is:  0.0005467135045095827\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.867697748717471e-06\n",
            " MSE of Test data at current Epoch is:  0.20893132167982895\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 719 is:  0.0005461845783658357\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.862751294388454e-06\n",
            " MSE of Test data at current Epoch is:  0.20896265182594498\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 720 is:  0.0005446740540611867\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.8462759892338505e-06\n",
            " MSE of Test data at current Epoch is:  0.20894556493154837\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 721 is:  0.0005442506771189861\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.838716186208169e-06\n",
            " MSE of Test data at current Epoch is:  0.2089821506007919\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 722 is:  0.0005430822114700734\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.81452732308949e-06\n",
            " MSE of Test data at current Epoch is:  0.2089654609416019\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 723 is:  0.0005417269595219856\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.784917755941458e-06\n",
            " MSE of Test data at current Epoch is:  0.2090390129156175\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 724 is:  0.0005406870215078215\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.7847362203810984e-06\n",
            " MSE of Test data at current Epoch is:  0.20896579265359547\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 725 is:  0.0005394516558570546\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.757995918535933e-06\n",
            " MSE of Test data at current Epoch is:  0.20904565783056886\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 726 is:  0.0005386625481805976\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.7583176503253453e-06\n",
            " MSE of Test data at current Epoch is:  0.20900054740187105\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 727 is:  0.0005373994000939323\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.73437320485113e-06\n",
            " MSE of Test data at current Epoch is:  0.20902935271575387\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 728 is:  0.0005366969051806409\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.721185128219564e-06\n",
            " MSE of Test data at current Epoch is:  0.20902539515406296\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 729 is:  0.0005346774921830945\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.693615067799625e-06\n",
            " MSE of Test data at current Epoch is:  0.2090845793540484\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 730 is:  0.0005347039605378463\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.6941928055686435e-06\n",
            " MSE of Test data at current Epoch is:  0.20900561929088377\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 731 is:  0.0005331486051648018\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.674133221492701e-06\n",
            " MSE of Test data at current Epoch is:  0.2090846421653555\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 732 is:  0.0005323668447922486\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.6649898020388425e-06\n",
            " MSE of Test data at current Epoch is:  0.20903738346777911\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 733 is:  0.0005313690415350265\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.655042292271847e-06\n",
            " MSE of Test data at current Epoch is:  0.20908265104211443\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 734 is:  0.0005298593214551438\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.6195914214506746e-06\n",
            " MSE of Test data at current Epoch is:  0.20907836963954862\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 735 is:  0.0005294333844655572\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.6230940640897357e-06\n",
            " MSE of Test data at current Epoch is:  0.2090826057430703\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 736 is:  0.0005281357337984583\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.6041275255870097e-06\n",
            " MSE of Test data at current Epoch is:  0.20907208693697496\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 737 is:  0.0005274723891428245\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.6015195681629026e-06\n",
            " MSE of Test data at current Epoch is:  0.2090937485087542\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 738 is:  0.0005261063193214123\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.5764316002308936e-06\n",
            " MSE of Test data at current Epoch is:  0.20910218674393619\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 739 is:  0.0005253040628263203\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.561851180106725e-06\n",
            " MSE of Test data at current Epoch is:  0.2091309665144758\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 740 is:  0.0005237566218432469\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.5481900145852157e-06\n",
            " MSE of Test data at current Epoch is:  0.20909627002309567\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 741 is:  0.0005231227909547204\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.5339194860633406e-06\n",
            " MSE of Test data at current Epoch is:  0.20913881249555769\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 742 is:  0.0005221803917272619\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.524649955931509e-06\n",
            " MSE of Test data at current Epoch is:  0.20909725852294472\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 743 is:  0.0005216886862521755\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.5191863880909416e-06\n",
            " MSE of Test data at current Epoch is:  0.20913824769242897\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 744 is:  0.0005197592087179808\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.4848058650432856e-06\n",
            " MSE of Test data at current Epoch is:  0.20915160245350836\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 745 is:  0.0005192751811555571\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.4788720175088736e-06\n",
            " MSE of Test data at current Epoch is:  0.20917253633327573\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 746 is:  0.0005181392462107574\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.461516003176364e-06\n",
            " MSE of Test data at current Epoch is:  0.2091509510055843\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 747 is:  0.0005169453855933685\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.4540213967588047e-06\n",
            " MSE of Test data at current Epoch is:  0.20917450843645116\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 748 is:  0.0005162016193744181\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.4348287408432672e-06\n",
            " MSE of Test data at current Epoch is:  0.2091693862996455\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 749 is:  0.0005151573702753581\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.432922015446796e-06\n",
            " MSE of Test data at current Epoch is:  0.20917889665883668\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 750 is:  0.0005145229286555178\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.4290910799571797e-06\n",
            " MSE of Test data at current Epoch is:  0.20916845159643424\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 751 is:  0.0005130181519958705\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.3873082107742653e-06\n",
            " MSE of Test data at current Epoch is:  0.20922030088978222\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 752 is:  0.0005125401160089904\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.3986613049842108e-06\n",
            " MSE of Test data at current Epoch is:  0.20915183873136736\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 753 is:  0.0005114887338876277\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.384079652640149e-06\n",
            " MSE of Test data at current Epoch is:  0.20922278032224534\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 754 is:  0.0005102374840276153\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.352163611126618e-06\n",
            " MSE of Test data at current Epoch is:  0.20921349193232547\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 755 is:  0.000509380786952324\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.3585211343359387e-06\n",
            " MSE of Test data at current Epoch is:  0.2092026634013929\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 756 is:  0.0005083765465772362\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.3396652069581126e-06\n",
            " MSE of Test data at current Epoch is:  0.20920300946030157\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 757 is:  0.0005076283999276908\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.3322826652659814e-06\n",
            " MSE of Test data at current Epoch is:  0.20924293309514408\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 758 is:  0.0005069424205963745\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.317306991690526e-06\n",
            " MSE of Test data at current Epoch is:  0.20921184589983083\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 759 is:  0.0005056502009920042\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.3019919397833267e-06\n",
            " MSE of Test data at current Epoch is:  0.20925517941221397\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 760 is:  0.0005047706459786252\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.2767938028256728e-06\n",
            " MSE of Test data at current Epoch is:  0.2092557608501615\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 761 is:  0.0005039329142674057\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.2804693356541775e-06\n",
            " MSE of Test data at current Epoch is:  0.20924988781484363\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 762 is:  0.0005028212997860785\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.2660555497710024e-06\n",
            " MSE of Test data at current Epoch is:  0.20924872205251518\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 763 is:  0.0005017792397553653\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.2465389780090238e-06\n",
            " MSE of Test data at current Epoch is:  0.20929062509086716\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 764 is:  0.0005009448008276706\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.2348266992964475e-06\n",
            " MSE of Test data at current Epoch is:  0.20926575374097373\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 765 is:  0.0004998747693114872\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.2237108643622868e-06\n",
            " MSE of Test data at current Epoch is:  0.20929788507019795\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 766 is:  0.0004997369910538695\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.221500163478134e-06\n",
            " MSE of Test data at current Epoch is:  0.20923367826749809\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 767 is:  0.000498215651134318\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.20918929867096e-06\n",
            " MSE of Test data at current Epoch is:  0.20930712739032334\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 768 is:  0.0004976781785570843\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.190845888317421e-06\n",
            " MSE of Test data at current Epoch is:  0.2092776578516382\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 769 is:  0.0004963946191874361\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.179455444377378e-06\n",
            " MSE of Test data at current Epoch is:  0.20933398688188132\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 770 is:  0.000495276341297111\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.1629897538079136e-06\n",
            " MSE of Test data at current Epoch is:  0.20930371079576618\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 771 is:  0.0004954722944700649\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.161074988463081e-06\n",
            " MSE of Test data at current Epoch is:  0.2093066150336989\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 772 is:  0.0004939211226763457\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.1436280581912115e-06\n",
            " MSE of Test data at current Epoch is:  0.2093001280998244\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 773 is:  0.000492752377194544\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.1325975648803967e-06\n",
            " MSE of Test data at current Epoch is:  0.20933856566303255\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 774 is:  0.0004924503699606631\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.129504100427335e-06\n",
            " MSE of Test data at current Epoch is:  0.20929101580135162\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 775 is:  0.0004914722269765727\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.116390925483273e-06\n",
            " MSE of Test data at current Epoch is:  0.20936101147598676\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 776 is:  0.0004898488056084966\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.0885788324621863e-06\n",
            " MSE of Test data at current Epoch is:  0.20936093567412475\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 777 is:  0.0004893411668664768\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.0803041113410614e-06\n",
            " MSE of Test data at current Epoch is:  0.20939409215087407\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 778 is:  0.0004886532572122983\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.0789275392024526e-06\n",
            " MSE of Test data at current Epoch is:  0.20936268495328716\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 779 is:  0.0004876645973121011\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.062515815782956e-06\n",
            " MSE of Test data at current Epoch is:  0.20938740271126619\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 780 is:  0.00048670710272958364\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.0544947325417094e-06\n",
            " MSE of Test data at current Epoch is:  0.20934795118545943\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 781 is:  0.0004860668002282474\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.0466628736703794e-06\n",
            " MSE of Test data at current Epoch is:  0.2093927823113737\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 782 is:  0.00048497956980463644\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.0351864550814522e-06\n",
            " MSE of Test data at current Epoch is:  0.20937586241847173\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 783 is:  0.0004840539029457972\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.0211309362065144e-06\n",
            " MSE of Test data at current Epoch is:  0.20939287969352316\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 784 is:  0.0004836385943597605\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  3.0155284838037647e-06\n",
            " MSE of Test data at current Epoch is:  0.20938033285678828\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 785 is:  0.00048223394265188015\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.9945804960370544e-06\n",
            " MSE of Test data at current Epoch is:  0.20941446361911184\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 786 is:  0.0004817418685289743\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.9906744866435185e-06\n",
            " MSE of Test data at current Epoch is:  0.20940655992032092\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 787 is:  0.00048038354781951417\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.9817743816445075e-06\n",
            " MSE of Test data at current Epoch is:  0.2094395229575417\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 788 is:  0.00047971017317693606\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.960447057060219e-06\n",
            " MSE of Test data at current Epoch is:  0.2094292396240779\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 789 is:  0.00047862534681741267\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.951878100990652e-06\n",
            " MSE of Test data at current Epoch is:  0.20945832322824498\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 790 is:  0.000478173048833579\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.943622446608204e-06\n",
            " MSE of Test data at current Epoch is:  0.2094084384880636\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 791 is:  0.0004773335752663005\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.9353151340973446e-06\n",
            " MSE of Test data at current Epoch is:  0.2094629724902666\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 792 is:  0.00047647884499179134\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.9221707166383264e-06\n",
            " MSE of Test data at current Epoch is:  0.20944359526183123\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 793 is:  0.00047548759898511815\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.916295033594477e-06\n",
            " MSE of Test data at current Epoch is:  0.20946430139833525\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 794 is:  0.0004746189287253934\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.909015595047321e-06\n",
            " MSE of Test data at current Epoch is:  0.2094633186164427\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 795 is:  0.00047421650518775574\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.8963675786837308e-06\n",
            " MSE of Test data at current Epoch is:  0.20948498686053454\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 796 is:  0.00047309353505294396\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.881305039808804e-06\n",
            " MSE of Test data at current Epoch is:  0.20948286791891346\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 797 is:  0.00047237561307089535\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.8738776425485925e-06\n",
            " MSE of Test data at current Epoch is:  0.2094931520577834\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 798 is:  0.0004714412884230499\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.8621673330429004e-06\n",
            " MSE of Test data at current Epoch is:  0.20947914093402453\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 799 is:  0.00047042843999312554\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.851622433695458e-06\n",
            " MSE of Test data at current Epoch is:  0.20950184347137074\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 800 is:  0.0004699539667257866\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.846223932138868e-06\n",
            " MSE of Test data at current Epoch is:  0.209482983154816\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 801 is:  0.0004688946497859017\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.830693111698954e-06\n",
            " MSE of Test data at current Epoch is:  0.20950772439448465\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 802 is:  0.0004681034786647492\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.826973121733842e-06\n",
            " MSE of Test data at current Epoch is:  0.20951058217322696\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 803 is:  0.00046727321699037417\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.805316684768627e-06\n",
            " MSE of Test data at current Epoch is:  0.20953422933340032\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 804 is:  0.00046638076893043605\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.800133389477146e-06\n",
            " MSE of Test data at current Epoch is:  0.2095447791029365\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 805 is:  0.0004659947442921438\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.79477736673597e-06\n",
            " MSE of Test data at current Epoch is:  0.20951403170034322\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 806 is:  0.00046506172143483555\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.7900398392572636e-06\n",
            " MSE of Test data at current Epoch is:  0.2095090514843258\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 807 is:  0.00046439775916291755\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.778371998124054e-06\n",
            " MSE of Test data at current Epoch is:  0.2095288505742926\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 808 is:  0.0004632894198736801\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.7674778440474697e-06\n",
            " MSE of Test data at current Epoch is:  0.20952045510947048\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 809 is:  0.00046254859306194365\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.7565846471861134e-06\n",
            " MSE of Test data at current Epoch is:  0.20957167909705482\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 810 is:  0.0004620228628668894\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.7435707066899775e-06\n",
            " MSE of Test data at current Epoch is:  0.2095542659338387\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 811 is:  0.0004608517865188269\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.7375730529735923e-06\n",
            " MSE of Test data at current Epoch is:  0.2095701583300821\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 812 is:  0.0004602101906289991\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.729215360957052e-06\n",
            " MSE of Test data at current Epoch is:  0.20956963213932472\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 813 is:  0.00045934243346719016\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.7126291538093407e-06\n",
            " MSE of Test data at current Epoch is:  0.20958527102766888\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 814 is:  0.000458829406360695\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.711134916225994e-06\n",
            " MSE of Test data at current Epoch is:  0.20957912012319693\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 815 is:  0.0004577977636383658\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.697297110836694e-06\n",
            " MSE of Test data at current Epoch is:  0.20959626720917995\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 816 is:  0.00045705515965592243\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.6918075360091666e-06\n",
            " MSE of Test data at current Epoch is:  0.20959347917518142\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 817 is:  0.0004566446789546314\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.6838063596902276e-06\n",
            " MSE of Test data at current Epoch is:  0.20959191299428817\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 818 is:  0.00045530836669123936\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.665542623100099e-06\n",
            " MSE of Test data at current Epoch is:  0.20963896485654485\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 819 is:  0.0004546326351658243\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.660468500781279e-06\n",
            " MSE of Test data at current Epoch is:  0.2096166241990506\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 820 is:  0.00045423210738599257\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.6553716751272966e-06\n",
            " MSE of Test data at current Epoch is:  0.20962322415349932\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 821 is:  0.0004529381274890383\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.6480481029102835e-06\n",
            " MSE of Test data at current Epoch is:  0.2096195180425602\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 822 is:  0.0004526860265207608\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.639593685057172e-06\n",
            " MSE of Test data at current Epoch is:  0.20963248198946757\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 823 is:  0.00045170447223578795\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.6303986055388673e-06\n",
            " MSE of Test data at current Epoch is:  0.20963640566274866\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 824 is:  0.00045124873640240256\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.6242801082765777e-06\n",
            " MSE of Test data at current Epoch is:  0.2096111251877111\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 825 is:  0.00045003455352072116\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.6008425127805313e-06\n",
            " MSE of Test data at current Epoch is:  0.20966034528219965\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 826 is:  0.00044910349793194173\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.605516317929398e-06\n",
            " MSE of Test data at current Epoch is:  0.2096583814199026\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 827 is:  0.00044899862213461665\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.5958302963460972e-06\n",
            " MSE of Test data at current Epoch is:  0.20964521332307978\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 828 is:  0.00044783781273232315\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.582908161765262e-06\n",
            " MSE of Test data at current Epoch is:  0.2096740927521141\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 829 is:  0.00044705075794720223\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.5789254638229973e-06\n",
            " MSE of Test data at current Epoch is:  0.2096751548830451\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 830 is:  0.00044652508106279366\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.563739118787734e-06\n",
            " MSE of Test data at current Epoch is:  0.2096724886600532\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 831 is:  0.0004460472544240363\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.564922394922448e-06\n",
            " MSE of Test data at current Epoch is:  0.20967265353507356\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 832 is:  0.00044506563788742015\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.547896886422791e-06\n",
            " MSE of Test data at current Epoch is:  0.2097006956388465\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 833 is:  0.00044446401966091487\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.5406868614076937e-06\n",
            " MSE of Test data at current Epoch is:  0.20969965933205248\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 834 is:  0.00044367330822682493\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.539396664422936e-06\n",
            " MSE of Test data at current Epoch is:  0.2096912051557819\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 835 is:  0.00044278636576624853\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.525611177954149e-06\n",
            " MSE of Test data at current Epoch is:  0.20969030112129752\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 836 is:  0.0004419685209741611\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.514437762304501e-06\n",
            " MSE of Test data at current Epoch is:  0.20970899710319604\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 837 is:  0.0004414520050074716\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.506958182513064e-06\n",
            " MSE of Test data at current Epoch is:  0.20972506000320434\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 838 is:  0.0004407693570228089\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.5006528102863824e-06\n",
            " MSE of Test data at current Epoch is:  0.20970712428288185\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 839 is:  0.0004398154298304325\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.486638432584301e-06\n",
            " MSE of Test data at current Epoch is:  0.2097526282415694\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 840 is:  0.00043931835315155765\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.4814297274049673e-06\n",
            " MSE of Test data at current Epoch is:  0.20972280869462662\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 841 is:  0.00043827244206791523\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.4742385857675017e-06\n",
            " MSE of Test data at current Epoch is:  0.20974724182278157\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 842 is:  0.0004377749500986731\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.4650889317386154e-06\n",
            " MSE of Test data at current Epoch is:  0.2097285126358057\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 843 is:  0.0004371312852866533\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.464809823172637e-06\n",
            " MSE of Test data at current Epoch is:  0.20972095121833434\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 844 is:  0.00043648568206809766\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.4516177615732866e-06\n",
            " MSE of Test data at current Epoch is:  0.20974567778986306\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 845 is:  0.0004354517607906864\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.440610384326382e-06\n",
            " MSE of Test data at current Epoch is:  0.20976842116181302\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 846 is:  0.0004348783103084251\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.4349597569223614e-06\n",
            " MSE of Test data at current Epoch is:  0.2097561670555413\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 847 is:  0.0004338937057704666\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.4213915153798084e-06\n",
            " MSE of Test data at current Epoch is:  0.20976305595910347\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 848 is:  0.00043359196809534097\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.4206844944049205e-06\n",
            " MSE of Test data at current Epoch is:  0.2097740605365818\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 849 is:  0.000432313172514556\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.4032484801677966e-06\n",
            " MSE of Test data at current Epoch is:  0.20980624570105386\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 850 is:  0.0004321725747242723\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.4037681028728614e-06\n",
            " MSE of Test data at current Epoch is:  0.2097566034691853\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 851 is:  0.00043167196894072226\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.3994824083722187e-06\n",
            " MSE of Test data at current Epoch is:  0.2097757456882965\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 852 is:  0.00043078974040261666\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.388805681072418e-06\n",
            " MSE of Test data at current Epoch is:  0.20978713086916537\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 853 is:  0.00042958195256027817\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.3790527648329108e-06\n",
            " MSE of Test data at current Epoch is:  0.20980513588234942\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 854 is:  0.0004294143275332963\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.374500396254402e-06\n",
            " MSE of Test data at current Epoch is:  0.20977432694109474\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 855 is:  0.00042829888348065774\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.3626539623747015e-06\n",
            " MSE of Test data at current Epoch is:  0.20980961664173803\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 856 is:  0.0004278063280993872\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.3572726311408148e-06\n",
            " MSE of Test data at current Epoch is:  0.2097920134442756\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 857 is:  0.0004271053447992127\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.3555140322033606e-06\n",
            " MSE of Test data at current Epoch is:  0.20981670539946695\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 858 is:  0.00042656588270955747\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.342966865461312e-06\n",
            " MSE of Test data at current Epoch is:  0.2098388160699231\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 859 is:  0.0004258544145799845\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.3349927439875707e-06\n",
            " MSE of Test data at current Epoch is:  0.20983004675196434\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 860 is:  0.00042493256160764395\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.328161636049955e-06\n",
            " MSE of Test data at current Epoch is:  0.2098452970226107\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 861 is:  0.00042418712478958597\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.3161527626487602e-06\n",
            " MSE of Test data at current Epoch is:  0.2098598242356546\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 862 is:  0.0004234427302378792\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.3076603515418535e-06\n",
            " MSE of Test data at current Epoch is:  0.20986831179386453\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 863 is:  0.00042308118699628864\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.3023707169828206e-06\n",
            " MSE of Test data at current Epoch is:  0.20985181937380137\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 864 is:  0.0004223424384706625\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.29666038687719e-06\n",
            " MSE of Test data at current Epoch is:  0.20986509992156652\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 865 is:  0.00042161943547135367\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.2928981211613775e-06\n",
            " MSE of Test data at current Epoch is:  0.20985066192861707\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 866 is:  0.00042110341687093353\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.2844850203465082e-06\n",
            " MSE of Test data at current Epoch is:  0.2098656833807115\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 867 is:  0.00042034543298617163\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.274497820688459e-06\n",
            " MSE of Test data at current Epoch is:  0.2098647979359858\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 868 is:  0.0004200736374401268\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.2733936231147975e-06\n",
            " MSE of Test data at current Epoch is:  0.20984899880351737\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 869 is:  0.00041885366489329944\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.256562927674053e-06\n",
            " MSE of Test data at current Epoch is:  0.20990754415872712\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 870 is:  0.0004184616297849227\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.2587700777492096e-06\n",
            " MSE of Test data at current Epoch is:  0.20988576921497737\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 871 is:  0.0004175793606669176\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.2479135139580086e-06\n",
            " MSE of Test data at current Epoch is:  0.20989337218355242\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 872 is:  0.0004171705885587469\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.2414807893242477e-06\n",
            " MSE of Test data at current Epoch is:  0.2098924746807305\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 873 is:  0.00041613325185954473\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.2326870270549444e-06\n",
            " MSE of Test data at current Epoch is:  0.2099104887234689\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 874 is:  0.00041548378076166503\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.223975462421578e-06\n",
            " MSE of Test data at current Epoch is:  0.20990518121960058\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 875 is:  0.000415146449529274\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.219685372182999e-06\n",
            " MSE of Test data at current Epoch is:  0.20989773029311057\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 876 is:  0.0004146827040568021\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.216182859204372e-06\n",
            " MSE of Test data at current Epoch is:  0.20991497439037565\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 877 is:  0.00041355676487609327\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.2029742798558873e-06\n",
            " MSE of Test data at current Epoch is:  0.2099310673993409\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 878 is:  0.0004131731408049268\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.2000099765434566e-06\n",
            " MSE of Test data at current Epoch is:  0.20992068813767836\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 879 is:  0.00041251536346977746\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.1900735146930803e-06\n",
            " MSE of Test data at current Epoch is:  0.20993286698293367\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 880 is:  0.00041165733299333766\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.1845458292638822e-06\n",
            " MSE of Test data at current Epoch is:  0.20992625665689144\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 881 is:  0.0004110497956739385\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.1796615971321596e-06\n",
            " MSE of Test data at current Epoch is:  0.20994123019392796\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 882 is:  0.0004103952074409849\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.1669805251084614e-06\n",
            " MSE of Test data at current Epoch is:  0.2099555020645361\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 883 is:  0.00040992026007830485\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.1635618072939196e-06\n",
            " MSE of Test data at current Epoch is:  0.20996105911342405\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 884 is:  0.00040909025989964296\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.1521457260368347e-06\n",
            " MSE of Test data at current Epoch is:  0.20995288588393307\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 885 is:  0.0004088301280508263\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.1535211838676426e-06\n",
            " MSE of Test data at current Epoch is:  0.20995505576638468\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 886 is:  0.00040808269197745774\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.1466424419940203e-06\n",
            " MSE of Test data at current Epoch is:  0.20997204852134463\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 887 is:  0.00040716911828883416\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.1331699544987176e-06\n",
            " MSE of Test data at current Epoch is:  0.20998459172801817\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 888 is:  0.00040675029726082695\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.1305461803371513e-06\n",
            " MSE of Test data at current Epoch is:  0.2099690074212411\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 889 is:  0.0004060421348895026\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.124281830191672e-06\n",
            " MSE of Test data at current Epoch is:  0.2099673005740183\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 890 is:  0.0004054349544918563\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.11707823097944e-06\n",
            " MSE of Test data at current Epoch is:  0.2099913603553552\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 891 is:  0.00040478838147723213\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.107867349654231e-06\n",
            " MSE of Test data at current Epoch is:  0.20997657790166532\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 892 is:  0.00040438083576673785\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.110429877160048e-06\n",
            " MSE of Test data at current Epoch is:  0.20995869269575831\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 893 is:  0.00040393738128369043\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.1025491184325114e-06\n",
            " MSE of Test data at current Epoch is:  0.2099716154777579\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 894 is:  0.0004028086219720074\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.0929775677991355e-06\n",
            " MSE of Test data at current Epoch is:  0.20999468855379924\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 895 is:  0.00040241637736275953\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.087991396961556e-06\n",
            " MSE of Test data at current Epoch is:  0.2099895883859983\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 896 is:  0.00040178835506036716\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.0822196057464232e-06\n",
            " MSE of Test data at current Epoch is:  0.21000978914026316\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 897 is:  0.0004009326572456893\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.073099184465962e-06\n",
            " MSE of Test data at current Epoch is:  0.21003692887292136\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 898 is:  0.00040055903411809863\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.0684922572559504e-06\n",
            " MSE of Test data at current Epoch is:  0.21001637240834722\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 899 is:  0.00039967647104241895\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.0550192810048503e-06\n",
            " MSE of Test data at current Epoch is:  0.21005528799721418\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 900 is:  0.0003991310102133779\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.0558269815478624e-06\n",
            " MSE of Test data at current Epoch is:  0.2100231043574096\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 901 is:  0.000398751716196472\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.0480899229603643e-06\n",
            " MSE of Test data at current Epoch is:  0.21001091451765228\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 902 is:  0.00039820133815833563\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.0417659048319342e-06\n",
            " MSE of Test data at current Epoch is:  0.21004933204248438\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 903 is:  0.0003975782670103479\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.0390431759719626e-06\n",
            " MSE of Test data at current Epoch is:  0.21003257051322957\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 904 is:  0.00039688557167927416\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.0284326638300744e-06\n",
            " MSE of Test data at current Epoch is:  0.21005096571284243\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 905 is:  0.00039637130004926193\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.0235454136625315e-06\n",
            " MSE of Test data at current Epoch is:  0.21004848082994898\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 906 is:  0.0003955655523674228\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.013932681033712e-06\n",
            " MSE of Test data at current Epoch is:  0.2100676540725129\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 907 is:  0.000394973141582046\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.01157341384019e-06\n",
            " MSE of Test data at current Epoch is:  0.2100632044029242\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 908 is:  0.0003944980786511216\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  2.006369228038967e-06\n",
            " MSE of Test data at current Epoch is:  0.21007925184907195\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 909 is:  0.00039406497142260985\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.999835330379231e-06\n",
            " MSE of Test data at current Epoch is:  0.21006432821060347\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 910 is:  0.0003934081206080313\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.9937916899237493e-06\n",
            " MSE of Test data at current Epoch is:  0.2100871726686868\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 911 is:  0.00039274300279900417\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.987837724932459e-06\n",
            " MSE of Test data at current Epoch is:  0.210086977883361\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 912 is:  0.0003922295877057727\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.981768317589759e-06\n",
            " MSE of Test data at current Epoch is:  0.2100957134660657\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 913 is:  0.00039134194353257484\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.9721544652985578e-06\n",
            " MSE of Test data at current Epoch is:  0.21010507700945497\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 914 is:  0.0003910987006877495\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.9719161612337686e-06\n",
            " MSE of Test data at current Epoch is:  0.21008094948014422\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 915 is:  0.0003903647543809501\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.9601883028805822e-06\n",
            " MSE of Test data at current Epoch is:  0.2101102232795665\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 916 is:  0.0003898837826541285\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.960678435262038e-06\n",
            " MSE of Test data at current Epoch is:  0.210098418712734\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 917 is:  0.0003893725808672846\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.9508004085756036e-06\n",
            " MSE of Test data at current Epoch is:  0.21010881628106515\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 918 is:  0.0003888173398961514\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.948851576152204e-06\n",
            " MSE of Test data at current Epoch is:  0.21009150696061657\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 919 is:  0.0003882287135056491\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.9385753559092323e-06\n",
            " MSE of Test data at current Epoch is:  0.21010527625757558\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 920 is:  0.00038746196956815896\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.936510629554681e-06\n",
            " MSE of Test data at current Epoch is:  0.21012341168132515\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 921 is:  0.0003872381279596957\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.9328470221455876e-06\n",
            " MSE of Test data at current Epoch is:  0.21010566264357775\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 922 is:  0.00038629942319213823\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.9187833747176328e-06\n",
            " MSE of Test data at current Epoch is:  0.21015379200107906\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 923 is:  0.0003856986678381706\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.9176168128515477e-06\n",
            " MSE of Test data at current Epoch is:  0.21013226259835877\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 924 is:  0.00038519436326096704\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.9081924489330783e-06\n",
            " MSE of Test data at current Epoch is:  0.2101481601508405\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 925 is:  0.0003846807357648237\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.9062242190279696e-06\n",
            " MSE of Test data at current Epoch is:  0.21014694866477368\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 926 is:  0.0003838960148892246\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.9001234565000762e-06\n",
            " MSE of Test data at current Epoch is:  0.21017028911012994\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 927 is:  0.00038348492937438633\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.8920192945102011e-06\n",
            " MSE of Test data at current Epoch is:  0.21017240326323236\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 928 is:  0.00038316585833983837\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.891037184162983e-06\n",
            " MSE of Test data at current Epoch is:  0.2101537514757941\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 929 is:  0.0003823575628526818\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.8838646411338484e-06\n",
            " MSE of Test data at current Epoch is:  0.21016640833166972\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 930 is:  0.00038207429610782136\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.8796102800781237e-06\n",
            " MSE of Test data at current Epoch is:  0.21017455605324145\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 931 is:  0.0003813127597154773\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.8713473958127748e-06\n",
            " MSE of Test data at current Epoch is:  0.21018060935925914\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 932 is:  0.0003808076703465058\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.8719107058333716e-06\n",
            " MSE of Test data at current Epoch is:  0.21015117964311675\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 933 is:  0.0003801149311747865\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.8602611827908488e-06\n",
            " MSE of Test data at current Epoch is:  0.21019084996705592\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 934 is:  0.00037949545588373076\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.859096267553262e-06\n",
            " MSE of Test data at current Epoch is:  0.2101855894744211\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 935 is:  0.00037928500997\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.8541721328164304e-06\n",
            " MSE of Test data at current Epoch is:  0.2101735286061404\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 936 is:  0.00037873547611400765\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.8475098562469671e-06\n",
            " MSE of Test data at current Epoch is:  0.21019815456446353\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 937 is:  0.000377876722541878\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.8439847628524388e-06\n",
            " MSE of Test data at current Epoch is:  0.21018625280966177\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 938 is:  0.0003775614049351322\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.8368005573370513e-06\n",
            " MSE of Test data at current Epoch is:  0.21018693334096378\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 939 is:  0.00037687209465010204\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.8291761075597198e-06\n",
            " MSE of Test data at current Epoch is:  0.21022137594456106\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 940 is:  0.0003764994887889429\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.8284044335710785e-06\n",
            " MSE of Test data at current Epoch is:  0.21019788090566813\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 941 is:  0.00037560402702059293\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.8148822130276437e-06\n",
            " MSE of Test data at current Epoch is:  0.21022561373007245\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 942 is:  0.00037531475574872084\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.816419696086487e-06\n",
            " MSE of Test data at current Epoch is:  0.21018955020633112\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 943 is:  0.00037463710566312266\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.8095977234188691e-06\n",
            " MSE of Test data at current Epoch is:  0.2102211689803491\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 944 is:  0.00037412623869076395\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.8042750217377074e-06\n",
            " MSE of Test data at current Epoch is:  0.21022215885545176\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 945 is:  0.00037390153632661354\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.8047600165585709e-06\n",
            " MSE of Test data at current Epoch is:  0.21022887457814574\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 946 is:  0.0003730012261494297\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.7925525874572962e-06\n",
            " MSE of Test data at current Epoch is:  0.21023787690510087\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 947 is:  0.0003726928433224212\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.7916347777685668e-06\n",
            " MSE of Test data at current Epoch is:  0.2102227246300256\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 948 is:  0.0003721089321810087\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.784445756403557e-06\n",
            " MSE of Test data at current Epoch is:  0.2102291182038605\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 949 is:  0.00037142571798616823\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.778337016826683e-06\n",
            " MSE of Test data at current Epoch is:  0.21025269485363474\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 950 is:  0.00037103157465769216\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.7755040961104518e-06\n",
            " MSE of Test data at current Epoch is:  0.2102330654108483\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 951 is:  0.00037052477934368134\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.771149049862817e-06\n",
            " MSE of Test data at current Epoch is:  0.21023413630591306\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 952 is:  0.0003699049742884995\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.764831076238907e-06\n",
            " MSE of Test data at current Epoch is:  0.21025441928467387\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 953 is:  0.00036925807787152875\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.7605514957202156e-06\n",
            " MSE of Test data at current Epoch is:  0.21027231521334283\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 954 is:  0.0003689248556596079\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.752400237323025e-06\n",
            " MSE of Test data at current Epoch is:  0.21025510230741146\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 955 is:  0.000368385987973539\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.748896960809502e-06\n",
            " MSE of Test data at current Epoch is:  0.21027097553928634\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 956 is:  0.0003678223948968292\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.7441736904834382e-06\n",
            " MSE of Test data at current Epoch is:  0.21027189374541227\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 957 is:  0.00036730011288132786\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.7381292167817725e-06\n",
            " MSE of Test data at current Epoch is:  0.21028601596864233\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 958 is:  0.0003666933795158413\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.731495710568623e-06\n",
            " MSE of Test data at current Epoch is:  0.21029714996825608\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 959 is:  0.0003663984922533111\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.7314080807526056e-06\n",
            " MSE of Test data at current Epoch is:  0.2102664772689521\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 960 is:  0.00036590241853599783\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.72554511722739e-06\n",
            " MSE of Test data at current Epoch is:  0.21030399221032056\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 961 is:  0.0003651952996689672\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.7188408622962912e-06\n",
            " MSE of Test data at current Epoch is:  0.21029000501231718\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 962 is:  0.00036492301637560065\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.7176297189467072e-06\n",
            " MSE of Test data at current Epoch is:  0.21027729530324146\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 963 is:  0.00036405917234135236\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.705038216640222e-06\n",
            " MSE of Test data at current Epoch is:  0.21031055656355155\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 964 is:  0.0003636815453100416\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.7043302906173633e-06\n",
            " MSE of Test data at current Epoch is:  0.21031696558515492\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 965 is:  0.00036332055200729224\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.7017859420853148e-06\n",
            " MSE of Test data at current Epoch is:  0.21031793530867318\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 966 is:  0.00036247559117637057\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.691923194328962e-06\n",
            " MSE of Test data at current Epoch is:  0.21033309565123717\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 967 is:  0.0003622346149302812\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.6902083551686028e-06\n",
            " MSE of Test data at current Epoch is:  0.2103174338453511\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 968 is:  0.0003615721023900917\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.686142020568142e-06\n",
            " MSE of Test data at current Epoch is:  0.21031545739300023\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 969 is:  0.000361173309007685\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.6796936775066894e-06\n",
            " MSE of Test data at current Epoch is:  0.21033773651218304\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 970 is:  0.0003606529522362928\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.6756697543308984e-06\n",
            " MSE of Test data at current Epoch is:  0.21034745903301308\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 971 is:  0.00036032605171054595\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.6754186790891074e-06\n",
            " MSE of Test data at current Epoch is:  0.2103203944446234\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 972 is:  0.000359791900072558\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.6661026743285998e-06\n",
            " MSE of Test data at current Epoch is:  0.2103386352284767\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 973 is:  0.0003592615931165272\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.6632807283776069e-06\n",
            " MSE of Test data at current Epoch is:  0.2103366721199807\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 974 is:  0.00035868982899077927\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.6576046921207129e-06\n",
            " MSE of Test data at current Epoch is:  0.2103589011370223\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 975 is:  0.0003581937645960405\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.6526373368269214e-06\n",
            " MSE of Test data at current Epoch is:  0.210355773512408\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 976 is:  0.00035760881477106245\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.650549034138052e-06\n",
            " MSE of Test data at current Epoch is:  0.21034397861162393\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 977 is:  0.0003572541981006669\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.6455415388636942e-06\n",
            " MSE of Test data at current Epoch is:  0.21034670503036332\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 978 is:  0.00035679001667856516\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.6415826482287589e-06\n",
            " MSE of Test data at current Epoch is:  0.21035630606680245\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 979 is:  0.0003562694557216073\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.6365861924847502e-06\n",
            " MSE of Test data at current Epoch is:  0.21036184880207906\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 980 is:  0.00035590018296820095\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.6325587796010608e-06\n",
            " MSE of Test data at current Epoch is:  0.21035091811026177\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 981 is:  0.0003550295918550814\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.6226564766197838e-06\n",
            " MSE of Test data at current Epoch is:  0.21038593387063276\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 982 is:  0.00035445491489096835\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.6209512934600529e-06\n",
            " MSE of Test data at current Epoch is:  0.21037519780182956\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 983 is:  0.0003544589748189919\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.6211953441456315e-06\n",
            " MSE of Test data at current Epoch is:  0.21035979642751254\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 984 is:  0.00035390851948319084\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.6124144422667935e-06\n",
            " MSE of Test data at current Epoch is:  0.2103953188739597\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 985 is:  0.000353164033204157\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.606318005746761e-06\n",
            " MSE of Test data at current Epoch is:  0.21040067203762383\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 986 is:  0.0003528355009293277\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.6051974048563721e-06\n",
            " MSE of Test data at current Epoch is:  0.21039470347951916\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 987 is:  0.0003523575751504027\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.6014948062046826e-06\n",
            " MSE of Test data at current Epoch is:  0.2104095529598925\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 988 is:  0.00035211428938413373\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.5978147449320588e-06\n",
            " MSE of Test data at current Epoch is:  0.21039486973027594\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 989 is:  0.000351394944921972\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.5900735316765812e-06\n",
            " MSE of Test data at current Epoch is:  0.21040793229932356\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 990 is:  0.00035097795765957223\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.58755184751266e-06\n",
            " MSE of Test data at current Epoch is:  0.21039600530629654\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 991 is:  0.0003502639592018865\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.581989174623626e-06\n",
            " MSE of Test data at current Epoch is:  0.2104212218958822\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 992 is:  0.0003499906727539266\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.5797489469694997e-06\n",
            " MSE of Test data at current Epoch is:  0.21042291621492112\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 993 is:  0.0003493478950924996\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.5720158460590418e-06\n",
            " MSE of Test data at current Epoch is:  0.2104248590723724\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 994 is:  0.0003488550161017255\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.5702599211203678e-06\n",
            " MSE of Test data at current Epoch is:  0.2104199569218277\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 995 is:  0.0003487519298824481\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.5697250327963094e-06\n",
            " MSE of Test data at current Epoch is:  0.21041134294222252\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 996 is:  0.0003479359776284702\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.5624562046842642e-06\n",
            " MSE of Test data at current Epoch is:  0.21044193174635617\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 997 is:  0.0003477083141841401\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.5562586396375e-06\n",
            " MSE of Test data at current Epoch is:  0.2104488508019476\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 998 is:  0.0003470153956077138\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.5528250419283664e-06\n",
            " MSE of Test data at current Epoch is:  0.21044219095132846\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n",
            "\n",
            "*Cost for Training data at Epoch: 999 is:  0.0003465593765416858\n",
            " Accuracy_Train:  0.9999999999999998\n",
            " Accuracy_Test:  0.76\n",
            " MSE of Training data at current Epoch is:  1.547741701494257e-06\n",
            " MSE of Test data at current Epoch is:  0.21044653534167967\n",
            " MAE of Training data at current Epoch is:  0.0\n",
            " MAE of Test data at current Epoch is:  12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvBuk4l1estI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "520dc96b-82c9-4161-9fcb-aa424fb0b6c9"
      },
      "source": [
        "#This part of the code will show the Graphs of the results obtained from the training and predicting of the data\r\n",
        "\r\n",
        "iterations=1000   #Set the iterations to the number of EPOCHS\r\n",
        "\r\n",
        "#Plotting the Cost Versus Epochs graph with labels\r\n",
        "plt.title(\"Cost vs Epochs\")\r\n",
        "plt.xlabel(\"Epochs\")\r\n",
        "plt.ylabel(\"Cost\")\r\n",
        "plt.plot(cost_tracker[1:iterations])\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#***********displaying mean squared error per epoch\r\n",
        "plt.figure()\r\n",
        "plt.title(\"Training and Cross Validation (MSE) per Epoch\")\r\n",
        "plt.xlabel(\"Epochs\")\r\n",
        "plt.ylabel(\"MSE\")\r\n",
        "plt.plot(MSE_Train[1:iterations],'b')\r\n",
        "plt.plot(MSE_Test[1:iterations],'r')\r\n",
        "plt.figure()\r\n",
        "\r\n",
        "#***********displaying mean absolute error per epoch\r\n",
        "plt.title(\"Training and Cross Validation (MAE) per Epoch\")\r\n",
        "plt.xlabel(\"Epochs\")\r\n",
        "plt.ylabel(\"MAE\")\r\n",
        "plt.plot(MAE_Train[1:iterations],'b')\r\n",
        "plt.plot(MAE_Test[1:iterations],'r')\r\n",
        "plt.figure()\r\n",
        "\r\n",
        "#***********displaying Accuracy per epoch\r\n",
        "plt.title(\"Training and Cross Validation (Accuracy) per Epoch\")\r\n",
        "plt.xlabel(\"Epochs\")\r\n",
        "plt.ylabel(\"Accuracy\")\r\n",
        "plt.plot(accuracy_train[1:iterations],'b')\r\n",
        "plt.plot(accuracy_test[1:iterations],'r')\r\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000,)\n",
            "0.0003465593765416858\n",
            "(array([999]),)\n",
            "[0.00034656]\n",
            "Minimum Cost:  0.0003465593765416858\n",
            "shape of cost tracker is:  (1000,)\n",
            "[0.00034656]\n",
            "Last cost 0.0003465593765416858\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8dc830dfd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}