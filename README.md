# Multilayer-Neural-Network-Python-Forward-Backward-prop-plus-Gradient-Descent-Weight-Initialization
Implementation of Neural network forward, backward propagation from scratch with Xavier and He Weight initialization and ADAM and RMSProp Optimizers
